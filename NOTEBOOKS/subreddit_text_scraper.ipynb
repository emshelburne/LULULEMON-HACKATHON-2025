{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e6829ac-2feb-441f-9823-fc3fbf0a1c7f",
   "metadata": {},
   "source": [
    "# Text Scraping Lululemon's Subreddit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f45f844-7678-47d9-81c9-492d8571f422",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9ac48e06-1b3a-4dd8-ba25-f8cc9daee548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import praw\n",
    "from praw.models import MoreComments\n",
    "import matplotlib as plt\n",
    "import re, pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime, timezone, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cfa28980-b7fb-4c70-92dd-ff0903377914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set user's data path\n",
    "\n",
    "PATH = f\"C:/Users/emshe/Desktop/BRAINSTATION/LULULEMON/DATA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "39aa2f77-876f-44aa-b80a-a2eddade659e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reads .env file into current directory\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ce1dc4ed-9062-42ce-ba1e-395779a85de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract reddit credentials from .env file\n",
    "\n",
    "reddit = praw.Reddit(client_id=os.getenv(\"REDDIT_CLIENT_ID\"),\n",
    "    client_secret=os.getenv(\"REDDIT_CLIENT_SECRET\"),\n",
    "    username=os.getenv(\"REDDIT_USERNAME\"),\n",
    "    password=os.getenv(\"REDDIT_PASSWORD\"),\n",
    "    user_agent=os.getenv(\"REDDIT_USER_AGENT\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "de1bba7d-ce13-4575-b5b8-54b08ef4856c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix subreddit as lululemon\n",
    "\n",
    "sub = reddit.subreddit(\"lululemon\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e7c212-fa67-40e1-872f-bfd63fe1382a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Helper functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9a7ec57d-8299-43dd-9343-252d47d0bae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean text\n",
    "\n",
    "def clean_text(s: str | None) -> str | None:\n",
    "    \n",
    "    '''\n",
    "    Clean string by substituting spaces for problematic characters\n",
    "    '''\n",
    "    \n",
    "    if s is None:\n",
    "        return None\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2f1f42ea-3989-4c86-b396-f9d0435ea174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get datetime from UTC timestamp\n",
    "\n",
    "def dt_from_utc(ts: float) -> pd.Timestamp:\n",
    "\n",
    "    '''\n",
    "    Returns pd.datetime object (still in UTC)\n",
    "    '''\n",
    "    \n",
    "    return pd.to_datetime(ts, unit=\"s\", utc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c31afab8-4692-43da-87bc-0723484c41b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to examine dataframes\n",
    "\n",
    "def examine_df(name,df,\n",
    "               include_stats = True,\n",
    "               include_sample = True):\n",
    "    \n",
    "    \"\"\"\n",
    "    Check basic info about a dataframe df\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n\\nNumber of records in the {name} is: {len(df)}\\n\")\n",
    "    print(f\"\\nNumber of features in the {name} is: {len(df.columns)}\\n\")\n",
    "    print(f\"The columns in the {name} are: {df.columns}\\n\")\n",
    "    print(f\"\\n Other info about {name}:\\n\")\n",
    "    display(df.info())\n",
    "    if include_stats == True:\n",
    "        print(f'\\n Basic statistical info about {name}:\\n')\n",
    "        display(df.describe())\n",
    "    if include_sample == True:\n",
    "        print(f\"\\n\\nSample of records in the {name}:\")\n",
    "        display(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864366ec-8c73-459e-a127-250ff8fb6bcc",
   "metadata": {},
   "source": [
    "## Test Reddit Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48f23269-c897-4e46-9a7a-9476fd450a4f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticated as: lulu_data_collector\n"
     ]
    }
   ],
   "source": [
    "# Test fetching my own username\n",
    "\n",
    "me = reddit.user.me()\n",
    "print(\"Authenticated as:\", me)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "62dbf052-1ca8-4036-9b98-daa6eba7250d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>link_flair_text</th>\n",
       "      <th>permalink</th>\n",
       "      <th>stickied</th>\n",
       "      <th>locked</th>\n",
       "      <th>upvote_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1n72lwa</td>\n",
       "      <td>2025-09-03 02:09:03+00:00</td>\n",
       "      <td>CooperDoo422</td>\n",
       "      <td>Mystic üîÆ‚ò™Ô∏èüíú</td>\n",
       "      <td>I ordered the Mystic Aligns from WMTM last wee...</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>Fit Pics</td>\n",
       "      <td>https://www.reddit.com/r/lululemon/comments/1n...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1n70wil</td>\n",
       "      <td>2025-09-03 00:49:54+00:00</td>\n",
       "      <td>painthrowaway852</td>\n",
       "      <td>Autumn Rust combos</td>\n",
       "      <td>Java, Black, Ivory, and Espresso - love the wa...</td>\n",
       "      <td>100</td>\n",
       "      <td>13</td>\n",
       "      <td>Fit Pics</td>\n",
       "      <td>https://www.reddit.com/r/lululemon/comments/1n...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1n70bqt</td>\n",
       "      <td>2025-09-03 00:23:19+00:00</td>\n",
       "      <td>PleaseNoCilantro</td>\n",
       "      <td>Purple or Green</td>\n",
       "      <td>Stuck with a tough choice between purple pacin...</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>Styling Advice</td>\n",
       "      <td>https://www.reddit.com/r/lululemon/comments/1n...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id                 timestamp            author               title  \\\n",
       "0  1n72lwa 2025-09-03 02:09:03+00:00      CooperDoo422         Mystic üîÆ‚ò™Ô∏èüíú   \n",
       "1  1n70wil 2025-09-03 00:49:54+00:00  painthrowaway852  Autumn Rust combos   \n",
       "2  1n70bqt 2025-09-03 00:23:19+00:00  PleaseNoCilantro     Purple or Green   \n",
       "\n",
       "                                                text  score  num_comments  \\\n",
       "0  I ordered the Mystic Aligns from WMTM last wee...     33             4   \n",
       "1  Java, Black, Ivory, and Espresso - love the wa...    100            13   \n",
       "2  Stuck with a tough choice between purple pacin...      2             8   \n",
       "\n",
       "  link_flair_text                                          permalink  \\\n",
       "0        Fit Pics  https://www.reddit.com/r/lululemon/comments/1n...   \n",
       "1        Fit Pics  https://www.reddit.com/r/lululemon/comments/1n...   \n",
       "2  Styling Advice  https://www.reddit.com/r/lululemon/comments/1n...   \n",
       "\n",
       "   stickied  locked  upvote_ratio  \n",
       "0     False   False          0.95  \n",
       "1     False   False          0.96  \n",
       "2     False   False          0.60  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try collecting 30 most recent posts\n",
    "\n",
    "rows = []\n",
    "for i, post in enumerate(sub.new(limit=30)):   # 30 most-recent\n",
    "    rows.append({\n",
    "        \"post_id\": post.id,\n",
    "        \"timestamp\": dt_from_utc(post.created_utc),\n",
    "        \"author\": str(post.author) if post.author else None,\n",
    "        \"title\": clean_text(post.title),\n",
    "        \"text\": clean_text(post.selftext) if getattr(post, \"selftext\", None) else None,\n",
    "        \"score\": post.score,\n",
    "        \"num_comments\": post.num_comments,\n",
    "        \"link_flair_text\": getattr(post, \"link_flair_text\", None),\n",
    "        \"permalink\": f\"https://www.reddit.com{post.permalink}\",\n",
    "        \"stickied\": post.stickied,\n",
    "        \"locked\": post.locked,\n",
    "        \"upvote_ratio\": getattr(post, \"upvote_ratio\", None),\n",
    "    })\n",
    "\n",
    "posts_df = pd.DataFrame(rows)\n",
    "print(posts_df.shape)\n",
    "posts_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f69a79f-66f0-47ad-b0c0-ebc3349dd8a6",
   "metadata": {},
   "source": [
    "## Collect Post Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea8d070-1dc1-4884-9df3-024d12014451",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "747c034e-f8ad-4fde-a7b6-47020784f706",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Function to fetch posts from subreddit\n",
    "\n",
    "def fetch_posts(subreddit_name = 'lululemon', \n",
    "                     limit:int = 500) -> pd.DataFrame:\n",
    "\n",
    "    \"\"\"\n",
    "    Define function to fetch most recent posts from subreddit\n",
    "    \"\"\"\n",
    "\n",
    "    start = time.time()\n",
    "    \n",
    "    rows = []\n",
    "    \n",
    "    # figure out checkpoint step size (10% increments)\n",
    "    checkpoint = max(1, limit // 10)\n",
    "\n",
    "    for i, post in enumerate(sub.new(limit=limit), start=1):\n",
    "        rows.append({\n",
    "            \"post_id\": post.id,\n",
    "            \"timestamp\": dt_from_utc(post.created_utc),\n",
    "            \"author\": str(post.author) if post.author else None,\n",
    "            \"title\": clean_text(post.title),\n",
    "            \"text\": clean_text(getattr(post, \"selftext\", None)),\n",
    "            \"score\": post.score,\n",
    "            \"num_comments\": post.num_comments,\n",
    "            \"link_flair_text\": getattr(post, \"link_flair_text\", None),\n",
    "            \"permalink\": f\"https://www.reddit.com{post.permalink}\",\n",
    "            \"stickied\": post.stickied,\n",
    "            \"locked\": post.locked,\n",
    "            \"upvote_ratio\": getattr(post, \"upvote_ratio\", None),\n",
    "        })\n",
    "\n",
    "        # print progress every 10%\n",
    "        if i % checkpoint == 0:\n",
    "            pct = int(i / limit * 100)\n",
    "            print(f\"... {pct}% ({i}/{limit}) posts scraped\")\n",
    "\n",
    "    print(f\"Done! Collected {len(rows)} posts from r/{subreddit_name}\")\n",
    "\n",
    "    end = time.time()\n",
    "    runtime = (end - start)/60\n",
    "    print(f\"Total runtime was {runtime:.2f} minutes.\")\n",
    "    \n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b97fc026-0519-455d-a02d-a21df4938e70",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Function to extract older posts from subreddit\n",
    "\n",
    "def fetch_from_time_range(subreddit_name: str = \"lululemon\", \n",
    "                           limit: int = 1000,\n",
    "                      time_filter: str = \"all\",  # \"all\", \"year\", \"month\", \"week\", \"day\"\n",
    "            start_dt: datetime | None = None,\n",
    "              end_dt: datetime | None = None,\n",
    "                        verbose: bool = True) -> pd.DataFrame:\n",
    "    \n",
    "    '''\n",
    "    Extract 1000 posts from given timeframe\n",
    "    '''\n",
    "    \n",
    "    sub = reddit.subreddit(subreddit_name)\n",
    "    rows = []\n",
    "\n",
    "    for i, post in enumerate(sub.top(time_filter=time_filter, limit=limit), start=1):\n",
    "        ts = dt_from_utc(post.created_utc)\n",
    "        rows.append({\n",
    "            \"post_id\": post.id,\n",
    "            \"timestamp\": ts,\n",
    "            \"author\": str(post.author) if post.author else None,\n",
    "            \"title\": clean_text(post.title),\n",
    "            \"text\": clean_text(getattr(post, \"selftext\", None)),\n",
    "            \"score\": post.score,\n",
    "            \"num_comments\": post.num_comments,\n",
    "            \"permalink\": f\"https://www.reddit.com{post.permalink}\",\n",
    "            \"link_flair_text\": getattr(post, \"link_flair_text\", None),\n",
    "        })\n",
    "        if verbose and i % 100 == 0:\n",
    "            print(f\"... {i} posts scraped\")\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    # Manual filter by datetime range\n",
    "    if start_dt:\n",
    "        df = df[df[\"timestamp\"] >= start_dt]\n",
    "    if end_dt:\n",
    "        df = df[df[\"timestamp\"] <= end_dt]\n",
    "\n",
    "    df = df.sort_values(\"timestamp\", ascending=False).reset_index(drop=True)\n",
    "    if verbose:\n",
    "        if not df.empty:\n",
    "            min_ts = df[\"timestamp\"].min().strftime(\"%Y-%m-%d\")\n",
    "            max_ts = df[\"timestamp\"].max().strftime(\"%Y-%m-%d\")\n",
    "            print(f\"Finished collecting {len(df)} posts from r/{subreddit_name} \"\n",
    "                  f\"covering {min_ts} to {max_ts}\")\n",
    "        else:\n",
    "            print(f\"No posts found for the given filters.\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ce4b5fc0-0d9b-42cf-84a4-a0ff2f617d13",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Function to set up month spans\n",
    "\n",
    "def month_spans(start_year: int = 2020, \n",
    "               start_month: int = 1) -> list[tuple[datetime, datetime]]:\n",
    "    \n",
    "    \"\"\"\n",
    "    Yield (start_dt, end_dt) UTC for each calendar month from start_month to current month.\n",
    "    \"\"\"\n",
    "    \n",
    "    spans = []\n",
    "    now = datetime.now(timezone.utc)\n",
    "    y, m = start_year, start_month\n",
    "    while (y < now.year) or (y == now.year and m <= now.month):\n",
    "        start_dt = datetime(y, m, 1, tzinfo=timezone.utc)\n",
    "        \n",
    "        # next month\n",
    "        if m == 12:\n",
    "            ny, nm = y + 1, 1\n",
    "        else:\n",
    "            ny, nm = y, m + 1\n",
    "        next_month_start = datetime(ny, nm, 1, tzinfo=timezone.utc)\n",
    "        end_dt = min(next_month_start - timedelta(seconds=1), now)  # don‚Äôt go beyond \"now\"\n",
    "        spans.append((start_dt, end_dt))\n",
    "        y, m = ny, nm\n",
    "    return spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8e9c2070-7dcd-4cfc-9008-0ec4b43f2929",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Function to scrape month by month\n",
    "\n",
    "def fetch_top_by_months(\n",
    "    subreddit_name: str = \"lululemon\",\n",
    "    start_year: int = 2020,\n",
    "    start_month: int = 1,\n",
    "    per_month_limit: int = 1000,\n",
    "    sleep_seconds: float = 1.0,\n",
    "    verbose: bool = True\n",
    ") -> pd.DataFrame:\n",
    "    \n",
    "    \"\"\"\n",
    "    Fetch top posts month by month and merge into a single dataframe.\n",
    "    \"\"\"\n",
    "    \n",
    "    spans = month_spans(start_year, start_month)\n",
    "    all_month_dfs: list[pd.DataFrame] = []\n",
    "\n",
    "    for i, (start_dt, end_dt) in enumerate(spans, start=1):\n",
    "        df_month = fetch_from_time_range(\n",
    "            subreddit_name=subreddit_name,\n",
    "            limit=per_month_limit,\n",
    "            time_filter=\"all\",\n",
    "            start_dt=start_dt,\n",
    "            end_dt=end_dt,\n",
    "            verbose=False\n",
    "        )\n",
    "        if verbose:\n",
    "            print(f\"[{i}/{len(spans)}] {start_dt.strftime('%Y-%m')} ‚Üí {len(df_month)} posts\")\n",
    "        all_month_dfs.append(df_month)\n",
    "        time.sleep(sleep_seconds)\n",
    "\n",
    "    if all_month_dfs:\n",
    "        combined = (\n",
    "            pd.concat(all_month_dfs, ignore_index=True)\n",
    "              .drop_duplicates(subset=\"post_id\")\n",
    "              .sort_values(\"timestamp\", ascending=False)\n",
    "              .reset_index(drop=True)\n",
    "        )\n",
    "    else:\n",
    "        combined = pd.DataFrame()\n",
    "\n",
    "    if verbose and not combined.empty:\n",
    "        min_ts = combined[\"timestamp\"].min().strftime(\"%Y-%m-%d\")\n",
    "        max_ts = combined[\"timestamp\"].max().strftime(\"%Y-%m-%d\")\n",
    "        print(f\"\\nCombined: {combined.shape[0]} unique posts covering {min_ts} ‚Üí {max_ts}\")\n",
    "\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6ca12ece-e82c-44b6-a329-15df27d78690",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Function to fetch all comments for a given post\n",
    "\n",
    "def fetch_comments_single_post(post_id: str, max_comments: int | None = None) -> pd.DataFrame:\n",
    "    \n",
    "    \"\"\"\n",
    "    Fetch all comments for a single post.\n",
    "    \"\"\"\n",
    "    \n",
    "    submission = reddit.submission(id=post_id)\n",
    "\n",
    "    submission.comments.replace_more(limit=None)  # expand all MoreComments\n",
    "\n",
    "    rows = []\n",
    "    count = 0\n",
    "    for c in submission.comments.list():\n",
    "        if isinstance(c, MoreComments):\n",
    "            continue\n",
    "        rows.append({\n",
    "            \"post_id\": post_id,\n",
    "            \"comment_id\": c.id,\n",
    "            \"timestamp\": dt_from_utc(c.created_utc),\n",
    "            \"author\": str(c.author) if c.author else None,\n",
    "            \"body\": clean_text(c.body),\n",
    "            \"score\": c.score,\n",
    "            \"is_submitter\": getattr(c, \"is_submitter\", None),\n",
    "            \"parent_id\": c.parent_id,   # t1_... (comment) or t3_... (post)\n",
    "            \"permalink\": f\"https://www.reddit.com{c.permalink}\",\n",
    "            \"depth\": c.depth,\n",
    "        })\n",
    "        count += 1\n",
    "        if max_comments and count >= max_comments:\n",
    "            break\n",
    "\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "34dab635-25f0-4bce-8e59-0b1dc8af1191",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Function to extract single dataframe of all comments\n",
    "\n",
    "def fetch_comments_from_posts( post_ids: list,\n",
    "                 max_comments_per_post: int | None = None ) -> pd.DataFrame:\n",
    "    \n",
    "    \"\"\"\n",
    "    Fetch comments for multiple Reddit posts, provided a list of post ids.\n",
    "    \"\"\"\n",
    "    \n",
    "    all_dfs = []\n",
    "    total = len(post_ids)\n",
    "\n",
    "    for idx, pid in enumerate(post_ids, start=1):\n",
    "        df = fetch_comments_single_post(pid, max_comments=max_comments_per_post)\n",
    "        all_dfs.append(df)\n",
    "        print(f\"[{idx}/{total}] Collected {len(df)} comments from post {pid}\\n\")\n",
    "\n",
    "    # Concatenate all into a single dataframe\n",
    "    combined = pd.concat(all_dfs, ignore_index=True) if all_dfs else pd.DataFrame()\n",
    "    \n",
    "    print(f\"\\nFinished collecting {combined.shape[0]} total comments across {total} posts.\")\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785bfd91-2506-40d7-8aaf-1a99e44c274b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Collect new posts and comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f651cfc-8681-4cf1-9c90-01f30bfb11a6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... 10% (200/2000) posts scraped\n",
      "... 20% (400/2000) posts scraped\n",
      "... 30% (600/2000) posts scraped\n",
      "... 40% (800/2000) posts scraped\n",
      "Done! Collected 995 posts from r/lululemon\n",
      "Total runtime was 0.32 minutes.\n"
     ]
    }
   ],
   "source": [
    "# Fetch posts\n",
    "\n",
    "new_posts_df = fetch_posts(limit = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18e4c806-0200-4ca6-bcf3-465b55a6b478",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I was shopping for a new skirt as a treat-yo-self and I saw the new Side-Pleat High-Rise Tennis Skirt. The red one priced at $98 but as it was a TYS purchase I decided to get it along with 3 other items. I got a notice that my item was shipped but awaiting carrier pick-up but that lasted so many days which is unusual for lulu. I contacted Lululemon to inquire and they said it was lost. They would refund me but seeing that the price has increased by then dollars for the skirt, I asked if they would just replace the order. The CSR said they need 100 items in order for a replacement to happen but it's available online. After some arm twisting, she put the order threw but told me that there was a good chance my order would get cancelled. I shop a lot at Lululemon and lately I feel like the customer service has been going way down. We pay a lot of money for the clothes and it just left a bad taste that I had to so much coaxing to get a reorder on a lost shipment because they use a bad carrier. Fingers crossed I actually get the celebratory skirt I ordered.\n"
     ]
    }
   ],
   "source": [
    "# Print example post\n",
    "\n",
    "post = new_posts_df['text'][0]\n",
    "print(post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00e0805e-ea21-4a14-b19f-c4e0bb4111d7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Number of records in the new posts dataframe is: 995\n",
      "\n",
      "\n",
      "Number of features in the new posts dataframe is: 12\n",
      "\n",
      "The columns in the new posts dataframe are: Index(['post_id', 'timestamp', 'author', 'title', 'text', 'score',\n",
      "       'num_comments', 'link_flair_text', 'permalink', 'stickied', 'locked',\n",
      "       'upvote_ratio'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      " Other info about new posts dataframe:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 995 entries, 0 to 994\n",
      "Data columns (total 12 columns):\n",
      " #   Column           Non-Null Count  Dtype              \n",
      "---  ------           --------------  -----              \n",
      " 0   post_id          995 non-null    object             \n",
      " 1   timestamp        995 non-null    datetime64[ns, UTC]\n",
      " 2   author           990 non-null    object             \n",
      " 3   title            995 non-null    object             \n",
      " 4   text             995 non-null    object             \n",
      " 5   score            995 non-null    int64              \n",
      " 6   num_comments     995 non-null    int64              \n",
      " 7   link_flair_text  995 non-null    object             \n",
      " 8   permalink        995 non-null    object             \n",
      " 9   stickied         995 non-null    bool               \n",
      " 10  locked           995 non-null    bool               \n",
      " 11  upvote_ratio     995 non-null    float64            \n",
      "dtypes: bool(2), datetime64[ns, UTC](1), float64(1), int64(2), object(6)\n",
      "memory usage: 79.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Basic statistical info about new posts dataframe:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>upvote_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>995.000000</td>\n",
       "      <td>995.000000</td>\n",
       "      <td>995.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>70.708543</td>\n",
       "      <td>15.688442</td>\n",
       "      <td>0.853698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>89.748091</td>\n",
       "      <td>22.499797</td>\n",
       "      <td>0.160594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.790000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.970000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1008.000000</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             score  num_comments  upvote_ratio\n",
       "count   995.000000    995.000000    995.000000\n",
       "mean     70.708543     15.688442      0.853698\n",
       "std      89.748091     22.499797      0.160594\n",
       "min       0.000000      0.000000      0.130000\n",
       "25%       7.000000      4.000000      0.790000\n",
       "50%      40.000000      9.000000      0.920000\n",
       "75%     100.000000     18.000000      0.970000\n",
       "max    1008.000000    243.000000      1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Sample of records in the new posts dataframe:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>link_flair_text</th>\n",
       "      <th>permalink</th>\n",
       "      <th>stickied</th>\n",
       "      <th>locked</th>\n",
       "      <th>upvote_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1n7q2s8</td>\n",
       "      <td>2025-09-03 20:31:13+00:00</td>\n",
       "      <td>berry_pink</td>\n",
       "      <td>Price change in a few days and bad CSR</td>\n",
       "      <td>I was shopping for a new skirt as a treat-yo-s...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>https://www.reddit.com/r/lululemon/comments/1n...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1n7po2x</td>\n",
       "      <td>2025-09-03 20:16:03+00:00</td>\n",
       "      <td>runandplay2</td>\n",
       "      <td>In Store Try On (Rockwood / New define Track t...</td>\n",
       "      <td>Sorry for the double post today but thought ot...</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>Fit Pics</td>\n",
       "      <td>https://www.reddit.com/r/lululemon/comments/1n...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1n7nh4p</td>\n",
       "      <td>2025-09-03 18:53:26+00:00</td>\n",
       "      <td>Puzzleheaded-Fan5586</td>\n",
       "      <td>Which bag for travel?</td>\n",
       "      <td>Looking for a safe crossbody bag for a Europea...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Product Question/Recommendation</td>\n",
       "      <td>https://www.reddit.com/r/lululemon/comments/1n...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1n7n9mb</td>\n",
       "      <td>2025-09-03 18:45:38+00:00</td>\n",
       "      <td>Ameeeekay</td>\n",
       "      <td>OOTD ü§çüñ§</td>\n",
       "      <td>Fast and Free High-Rise Classic-Fit Split Shor...</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>Fit Pics</td>\n",
       "      <td>https://www.reddit.com/r/lululemon/comments/1n...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1n7n4e1</td>\n",
       "      <td>2025-09-03 18:40:03+00:00</td>\n",
       "      <td>Apprehensive_Place51</td>\n",
       "      <td>insulated os collared jacket sizing</td>\n",
       "      <td>could anyone give me sizing advice on this? i'...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Sizing Advice</td>\n",
       "      <td>https://www.reddit.com/r/lululemon/comments/1n...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id                 timestamp                author  \\\n",
       "0  1n7q2s8 2025-09-03 20:31:13+00:00            berry_pink   \n",
       "1  1n7po2x 2025-09-03 20:16:03+00:00           runandplay2   \n",
       "2  1n7nh4p 2025-09-03 18:53:26+00:00  Puzzleheaded-Fan5586   \n",
       "3  1n7n9mb 2025-09-03 18:45:38+00:00             Ameeeekay   \n",
       "4  1n7n4e1 2025-09-03 18:40:03+00:00  Apprehensive_Place51   \n",
       "\n",
       "                                               title  \\\n",
       "0             Price change in a few days and bad CSR   \n",
       "1  In Store Try On (Rockwood / New define Track t...   \n",
       "2                              Which bag for travel?   \n",
       "3                                            OOTD ü§çüñ§   \n",
       "4                insulated os collared jacket sizing   \n",
       "\n",
       "                                                text  score  num_comments  \\\n",
       "0  I was shopping for a new skirt as a treat-yo-s...      2             0   \n",
       "1  Sorry for the double post today but thought ot...     14             1   \n",
       "2  Looking for a safe crossbody bag for a Europea...      2             2   \n",
       "3  Fast and Free High-Rise Classic-Fit Split Shor...     29             1   \n",
       "4  could anyone give me sizing advice on this? i'...      1             4   \n",
       "\n",
       "                   link_flair_text  \\\n",
       "0                       Discussion   \n",
       "1                         Fit Pics   \n",
       "2  Product Question/Recommendation   \n",
       "3                         Fit Pics   \n",
       "4                    Sizing Advice   \n",
       "\n",
       "                                           permalink  stickied  locked  \\\n",
       "0  https://www.reddit.com/r/lululemon/comments/1n...     False   False   \n",
       "1  https://www.reddit.com/r/lululemon/comments/1n...     False   False   \n",
       "2  https://www.reddit.com/r/lululemon/comments/1n...     False   False   \n",
       "3  https://www.reddit.com/r/lululemon/comments/1n...     False   False   \n",
       "4  https://www.reddit.com/r/lululemon/comments/1n...     False   False   \n",
       "\n",
       "   upvote_ratio  \n",
       "0          1.00  \n",
       "1          1.00  \n",
       "2          0.75  \n",
       "3          0.89  \n",
       "4          0.66  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Examine posts dataframe\n",
    "\n",
    "examine_df('new posts dataframe', new_posts_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058c816e-f4c5-41d8-807a-44d55a383d61",
   "metadata": {},
   "source": [
    "### Collect Older Posts (Attempt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7501006d-d802-49b6-a3ea-6ce61ae1ebe2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... 100 posts scraped\n",
      "... 200 posts scraped\n",
      "... 300 posts scraped\n",
      "... 400 posts scraped\n",
      "... 500 posts scraped\n",
      "... 600 posts scraped\n",
      "... 700 posts scraped\n",
      "... 800 posts scraped\n",
      "... 900 posts scraped\n",
      "Finished collecting 212 posts from r/lululemon covering 2021-01-01 to 2021-12-26\n",
      "\n",
      "\n",
      "Number of records in the older posts dataframe is: 999\n",
      "\n",
      "\n",
      "Number of features in the older posts dataframe is: 9\n",
      "\n",
      "The columns in the older posts dataframe are: Index(['post_id', 'timestamp', 'author', 'title', 'text', 'score',\n",
      "       'num_comments', 'permalink', 'link_flair_text'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      " Other info about older posts dataframe:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 999 entries, 0 to 998\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Non-Null Count  Dtype              \n",
      "---  ------           --------------  -----              \n",
      " 0   post_id          999 non-null    object             \n",
      " 1   timestamp        999 non-null    datetime64[ns, UTC]\n",
      " 2   author           919 non-null    object             \n",
      " 3   title            999 non-null    object             \n",
      " 4   text             999 non-null    object             \n",
      " 5   score            999 non-null    int64              \n",
      " 6   num_comments     999 non-null    int64              \n",
      " 7   permalink        999 non-null    object             \n",
      " 8   link_flair_text  992 non-null    object             \n",
      "dtypes: datetime64[ns, UTC](1), int64(2), object(6)\n",
      "memory usage: 70.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Basic statistical info about older posts dataframe:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>999.000000</td>\n",
       "      <td>999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>796.542543</td>\n",
       "      <td>62.826827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1627.504503</td>\n",
       "      <td>60.987260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>451.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>510.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>602.000000</td>\n",
       "      <td>46.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>782.500000</td>\n",
       "      <td>74.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>49038.000000</td>\n",
       "      <td>1002.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              score  num_comments\n",
       "count    999.000000    999.000000\n",
       "mean     796.542543     62.826827\n",
       "std     1627.504503     60.987260\n",
       "min      451.000000      2.000000\n",
       "25%      510.000000     31.000000\n",
       "50%      602.000000     46.000000\n",
       "75%      782.500000     74.000000\n",
       "max    49038.000000   1002.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Sample of records in the older posts dataframe:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>permalink</th>\n",
       "      <th>link_flair_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g6dpgp</td>\n",
       "      <td>2020-04-23 01:23:37+00:00</td>\n",
       "      <td>MichelleT88</td>\n",
       "      <td>So these came today. I'm tranfeminine and have...</td>\n",
       "      <td></td>\n",
       "      <td>484</td>\n",
       "      <td>82</td>\n",
       "      <td>https://www.reddit.com/r/lululemon/comments/g6...</td>\n",
       "      <td>Fit Pics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>g7k04x</td>\n",
       "      <td>2020-04-25 00:27:06+00:00</td>\n",
       "      <td>crystalk_13</td>\n",
       "      <td>couldn‚Äôt relate more üòÇ</td>\n",
       "      <td></td>\n",
       "      <td>461</td>\n",
       "      <td>19</td>\n",
       "      <td>https://www.reddit.com/r/lululemon/comments/g7...</td>\n",
       "      <td>Misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>giw8ut</td>\n",
       "      <td>2020-05-13 10:11:41+00:00</td>\n",
       "      <td>einaeb1</td>\n",
       "      <td>On Wednesdays we wear pink (and purple?)</td>\n",
       "      <td></td>\n",
       "      <td>482</td>\n",
       "      <td>37</td>\n",
       "      <td>https://www.reddit.com/r/lululemon/comments/gi...</td>\n",
       "      <td>Collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gk10a9</td>\n",
       "      <td>2020-05-15 02:50:13+00:00</td>\n",
       "      <td>isappleworthit</td>\n",
       "      <td>25% Off Lululemon Link</td>\n",
       "      <td>**Expires May 21 (11:59 PST)** **[Here is am t...</td>\n",
       "      <td>948</td>\n",
       "      <td>1002</td>\n",
       "      <td>https://www.reddit.com/r/lululemon/comments/gk...</td>\n",
       "      <td>Discussion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>go77dy</td>\n",
       "      <td>2020-05-21 22:51:17+00:00</td>\n",
       "      <td>minidontsurf</td>\n",
       "      <td>Daydream collection! Still trying to snag the ...</td>\n",
       "      <td></td>\n",
       "      <td>476</td>\n",
       "      <td>43</td>\n",
       "      <td>https://www.reddit.com/r/lululemon/comments/go...</td>\n",
       "      <td>Collection</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  post_id                 timestamp          author  \\\n",
       "0  g6dpgp 2020-04-23 01:23:37+00:00     MichelleT88   \n",
       "1  g7k04x 2020-04-25 00:27:06+00:00     crystalk_13   \n",
       "2  giw8ut 2020-05-13 10:11:41+00:00         einaeb1   \n",
       "3  gk10a9 2020-05-15 02:50:13+00:00  isappleworthit   \n",
       "4  go77dy 2020-05-21 22:51:17+00:00    minidontsurf   \n",
       "\n",
       "                                               title  \\\n",
       "0  So these came today. I'm tranfeminine and have...   \n",
       "1                             couldn‚Äôt relate more üòÇ   \n",
       "2           On Wednesdays we wear pink (and purple?)   \n",
       "3                             25% Off Lululemon Link   \n",
       "4  Daydream collection! Still trying to snag the ...   \n",
       "\n",
       "                                                text  score  num_comments  \\\n",
       "0                                                       484            82   \n",
       "1                                                       461            19   \n",
       "2                                                       482            37   \n",
       "3  **Expires May 21 (11:59 PST)** **[Here is am t...    948          1002   \n",
       "4                                                       476            43   \n",
       "\n",
       "                                           permalink link_flair_text  \n",
       "0  https://www.reddit.com/r/lululemon/comments/g6...        Fit Pics  \n",
       "1  https://www.reddit.com/r/lululemon/comments/g7...            Misc  \n",
       "2  https://www.reddit.com/r/lululemon/comments/gi...      Collection  \n",
       "3  https://www.reddit.com/r/lululemon/comments/gk...      Discussion  \n",
       "4  https://www.reddit.com/r/lululemon/comments/go...      Collection  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test collecting posts from 2021\n",
    "\n",
    "posts_df_2021 = fetch_from_time_range(\n",
    "     start_dt = datetime(2021,1,1, tzinfo=timezone.utc),\n",
    "       end_dt = datetime(2021,12,31,23,59, tzinfo=timezone.utc),\n",
    "      verbose = True\n",
    ")\n",
    "\n",
    "examine_df('older posts dataframe', posts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d9cf75bf-3e9a-4795-be9c-bbc4906b4664",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/45] 2022-01 ‚Üí 8 posts\n",
      "[2/45] 2022-02 ‚Üí 11 posts\n",
      "[3/45] 2022-03 ‚Üí 9 posts\n",
      "[4/45] 2022-04 ‚Üí 11 posts\n",
      "[5/45] 2022-05 ‚Üí 11 posts\n",
      "[6/45] 2022-06 ‚Üí 12 posts\n",
      "[7/45] 2022-07 ‚Üí 11 posts\n",
      "[8/45] 2022-08 ‚Üí 6 posts\n",
      "[9/45] 2022-09 ‚Üí 13 posts\n",
      "[10/45] 2022-10 ‚Üí 17 posts\n",
      "[11/45] 2022-11 ‚Üí 10 posts\n",
      "[12/45] 2022-12 ‚Üí 12 posts\n",
      "[13/45] 2023-01 ‚Üí 14 posts\n",
      "[14/45] 2023-02 ‚Üí 6 posts\n",
      "[15/45] 2023-03 ‚Üí 9 posts\n",
      "[16/45] 2023-04 ‚Üí 14 posts\n",
      "[17/45] 2023-05 ‚Üí 9 posts\n",
      "[18/45] 2023-06 ‚Üí 10 posts\n",
      "[19/45] 2023-07 ‚Üí 5 posts\n",
      "[20/45] 2023-08 ‚Üí 1 posts\n",
      "[21/45] 2023-09 ‚Üí 5 posts\n",
      "[22/45] 2023-10 ‚Üí 7 posts\n",
      "[23/45] 2023-11 ‚Üí 11 posts\n",
      "[24/45] 2023-12 ‚Üí 9 posts\n",
      "[25/45] 2024-01 ‚Üí 13 posts\n",
      "[26/45] 2024-02 ‚Üí 7 posts\n",
      "[27/45] 2024-03 ‚Üí 11 posts\n",
      "[28/45] 2024-04 ‚Üí 10 posts\n",
      "[29/45] 2024-05 ‚Üí 10 posts\n",
      "[30/45] 2024-06 ‚Üí 8 posts\n",
      "[31/45] 2024-07 ‚Üí 14 posts\n",
      "[32/45] 2024-08 ‚Üí 22 posts\n",
      "[33/45] 2024-09 ‚Üí 40 posts\n",
      "[34/45] 2024-10 ‚Üí 65 posts\n",
      "[35/45] 2024-11 ‚Üí 73 posts\n",
      "[36/45] 2024-12 ‚Üí 11 posts\n",
      "[37/45] 2025-01 ‚Üí 13 posts\n",
      "[38/45] 2025-02 ‚Üí 15 posts\n",
      "[39/45] 2025-03 ‚Üí 12 posts\n",
      "[40/45] 2025-04 ‚Üí 15 posts\n",
      "[41/45] 2025-05 ‚Üí 12 posts\n",
      "[42/45] 2025-06 ‚Üí 11 posts\n",
      "[43/45] 2025-07 ‚Üí 6 posts\n",
      "[44/45] 2025-08 ‚Üí 4 posts\n",
      "[45/45] 2025-09 ‚Üí 0 posts\n",
      "\n",
      "Combined: 603 unique posts covering 2022-01-03 ‚Üí 2025-08-31\n",
      "\n",
      "\n",
      "Number of records in the all posts dataframe is: 603\n",
      "\n",
      "\n",
      "Number of features in the all posts dataframe is: 9\n",
      "\n",
      "The columns in the all posts dataframe are: Index(['post_id', 'timestamp', 'author', 'title', 'text', 'score',\n",
      "       'num_comments', 'permalink', 'link_flair_text'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      " Other info about all posts dataframe:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 603 entries, 0 to 602\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Non-Null Count  Dtype              \n",
      "---  ------           --------------  -----              \n",
      " 0   post_id          603 non-null    object             \n",
      " 1   timestamp        603 non-null    datetime64[ns, UTC]\n",
      " 2   author           545 non-null    object             \n",
      " 3   title            603 non-null    object             \n",
      " 4   text             603 non-null    object             \n",
      " 5   score            603 non-null    int64              \n",
      " 6   num_comments     603 non-null    int64              \n",
      " 7   permalink        603 non-null    object             \n",
      " 8   link_flair_text  603 non-null    object             \n",
      "dtypes: datetime64[ns, UTC](1), int64(2), object(6)\n",
      "memory usage: 42.5+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Basic statistical info about all posts dataframe:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>603.000000</td>\n",
       "      <td>603.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>866.354892</td>\n",
       "      <td>69.308458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2072.285649</td>\n",
       "      <td>62.169373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>450.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>513.500000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>615.000000</td>\n",
       "      <td>47.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>840.500000</td>\n",
       "      <td>84.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>49047.000000</td>\n",
       "      <td>438.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              score  num_comments\n",
       "count    603.000000    603.000000\n",
       "mean     866.354892     69.308458\n",
       "std     2072.285649     62.169373\n",
       "min      450.000000      2.000000\n",
       "25%      513.500000     31.000000\n",
       "50%      615.000000     47.000000\n",
       "75%      840.500000     84.000000\n",
       "max    49047.000000    438.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Sample of records in the all posts dataframe:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>permalink</th>\n",
       "      <th>link_flair_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1n4i5ke</td>\n",
       "      <td>2025-08-31 01:27:26+00:00</td>\n",
       "      <td>burpling</td>\n",
       "      <td>A girl in a group of teenagers (scary) told me...</td>\n",
       "      <td>I was wearing this admittedly funny mix with a...</td>\n",
       "      <td>728</td>\n",
       "      <td>53</td>\n",
       "      <td>https://www.reddit.com/r/lululemon/comments/1n...</td>\n",
       "      <td>Fit Pics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1mxsau6</td>\n",
       "      <td>2025-08-23 04:46:22+00:00</td>\n",
       "      <td>taztazz895</td>\n",
       "      <td>First post. Kinda nervous üòÜ</td>\n",
       "      <td>Fell in love with goodnight plum üíü</td>\n",
       "      <td>528</td>\n",
       "      <td>38</td>\n",
       "      <td>https://www.reddit.com/r/lululemon/comments/1m...</td>\n",
       "      <td>Fit Pics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1mlbcrx</td>\n",
       "      <td>2025-08-09 00:10:54+00:00</td>\n",
       "      <td>tinanguyenn</td>\n",
       "      <td>i can‚Äôt be the only one ü§™</td>\n",
       "      <td>finally did laundry after 2.5 weeks of workout...</td>\n",
       "      <td>622</td>\n",
       "      <td>113</td>\n",
       "      <td>https://www.reddit.com/r/lululemon/comments/1m...</td>\n",
       "      <td>Collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1mjjvwr</td>\n",
       "      <td>2025-08-06 23:13:34+00:00</td>\n",
       "      <td>Alex_daisy13</td>\n",
       "      <td>What in Gilead is this thing???</td>\n",
       "      <td>\"Blessed be the fruit\" I guess.</td>\n",
       "      <td>1005</td>\n",
       "      <td>83</td>\n",
       "      <td>https://www.reddit.com/r/lululemon/comments/1m...</td>\n",
       "      <td>Discussion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1mcogbm</td>\n",
       "      <td>2025-07-29 21:41:25+00:00</td>\n",
       "      <td>xoghostbaby</td>\n",
       "      <td>fog green matching set :)</td>\n",
       "      <td>i‚Äôm wearing swiftly tech cropped short sleeve ...</td>\n",
       "      <td>621</td>\n",
       "      <td>8</td>\n",
       "      <td>https://www.reddit.com/r/lululemon/comments/1m...</td>\n",
       "      <td>Fit Pics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id                 timestamp        author  \\\n",
       "0  1n4i5ke 2025-08-31 01:27:26+00:00      burpling   \n",
       "1  1mxsau6 2025-08-23 04:46:22+00:00    taztazz895   \n",
       "2  1mlbcrx 2025-08-09 00:10:54+00:00   tinanguyenn   \n",
       "3  1mjjvwr 2025-08-06 23:13:34+00:00  Alex_daisy13   \n",
       "4  1mcogbm 2025-07-29 21:41:25+00:00   xoghostbaby   \n",
       "\n",
       "                                               title  \\\n",
       "0  A girl in a group of teenagers (scary) told me...   \n",
       "1                        First post. Kinda nervous üòÜ   \n",
       "2                          i can‚Äôt be the only one ü§™   \n",
       "3                    What in Gilead is this thing???   \n",
       "4                          fog green matching set :)   \n",
       "\n",
       "                                                text  score  num_comments  \\\n",
       "0  I was wearing this admittedly funny mix with a...    728            53   \n",
       "1                 Fell in love with goodnight plum üíü    528            38   \n",
       "2  finally did laundry after 2.5 weeks of workout...    622           113   \n",
       "3                    \"Blessed be the fruit\" I guess.   1005            83   \n",
       "4  i‚Äôm wearing swiftly tech cropped short sleeve ...    621             8   \n",
       "\n",
       "                                           permalink link_flair_text  \n",
       "0  https://www.reddit.com/r/lululemon/comments/1n...        Fit Pics  \n",
       "1  https://www.reddit.com/r/lululemon/comments/1m...        Fit Pics  \n",
       "2  https://www.reddit.com/r/lululemon/comments/1m...      Collection  \n",
       "3  https://www.reddit.com/r/lululemon/comments/1m...      Discussion  \n",
       "4  https://www.reddit.com/r/lululemon/comments/1m...        Fit Pics  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Collect month by month from 2020 till the present\n",
    "\n",
    "posts_df = fetch_top_by_months(start_year=2022, start_month=1)\n",
    "\n",
    "examine_df('all posts dataframe', posts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3b5e54d6-99e7-42da-959b-d68cf0687610",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Number of records in the all posts is: 1593\n",
      "\n",
      "\n",
      "Number of features in the all posts is: 12\n",
      "\n",
      "The columns in the all posts are: Index(['post_id', 'timestamp', 'author', 'title', 'text', 'score',\n",
      "       'num_comments', 'link_flair_text', 'permalink', 'stickied', 'locked',\n",
      "       'upvote_ratio'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      " Other info about all posts:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1593 entries, 0 to 1592\n",
      "Data columns (total 12 columns):\n",
      " #   Column           Non-Null Count  Dtype              \n",
      "---  ------           --------------  -----              \n",
      " 0   post_id          1593 non-null   object             \n",
      " 1   timestamp        1593 non-null   datetime64[ns, UTC]\n",
      " 2   author           1530 non-null   object             \n",
      " 3   title            1593 non-null   object             \n",
      " 4   text             1593 non-null   object             \n",
      " 5   score            1593 non-null   int64              \n",
      " 6   num_comments     1593 non-null   int64              \n",
      " 7   link_flair_text  1593 non-null   object             \n",
      " 8   permalink        1593 non-null   object             \n",
      " 9   stickied         995 non-null    object             \n",
      " 10  locked           995 non-null    object             \n",
      " 11  upvote_ratio     995 non-null    float64            \n",
      "dtypes: datetime64[ns, UTC](1), float64(1), int64(2), object(8)\n",
      "memory usage: 149.5+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Basic statistical info about all posts:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>upvote_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1593.000000</td>\n",
       "      <td>1593.000000</td>\n",
       "      <td>995.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>369.907721</td>\n",
       "      <td>35.849341</td>\n",
       "      <td>0.853698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1333.332917</td>\n",
       "      <td>49.496192</td>\n",
       "      <td>0.160594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.790000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>120.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>544.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>0.970000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>49047.000000</td>\n",
       "      <td>438.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              score  num_comments  upvote_ratio\n",
       "count   1593.000000   1593.000000    995.000000\n",
       "mean     369.907721     35.849341      0.853698\n",
       "std     1333.332917     49.496192      0.160594\n",
       "min        0.000000      0.000000      0.130000\n",
       "25%       25.000000      7.000000      0.790000\n",
       "50%      120.000000     18.000000      0.920000\n",
       "75%      544.000000     44.000000      0.970000\n",
       "max    49047.000000    438.000000      1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Sample of records in the all posts:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>link_flair_text</th>\n",
       "      <th>permalink</th>\n",
       "      <th>stickied</th>\n",
       "      <th>locked</th>\n",
       "      <th>upvote_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1n7q2s8</td>\n",
       "      <td>2025-09-03 20:31:13+00:00</td>\n",
       "      <td>berry_pink</td>\n",
       "      <td>Price change in a few days and bad CSR</td>\n",
       "      <td>I was shopping for a new skirt as a treat-yo-s...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>https://www.reddit.com/r/lululemon/comments/1n...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1n7po2x</td>\n",
       "      <td>2025-09-03 20:16:03+00:00</td>\n",
       "      <td>runandplay2</td>\n",
       "      <td>In Store Try On (Rockwood / New define Track t...</td>\n",
       "      <td>Sorry for the double post today but thought ot...</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>Fit Pics</td>\n",
       "      <td>https://www.reddit.com/r/lululemon/comments/1n...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1n7nh4p</td>\n",
       "      <td>2025-09-03 18:53:26+00:00</td>\n",
       "      <td>Puzzleheaded-Fan5586</td>\n",
       "      <td>Which bag for travel?</td>\n",
       "      <td>Looking for a safe crossbody bag for a Europea...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Product Question/Recommendation</td>\n",
       "      <td>https://www.reddit.com/r/lululemon/comments/1n...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1n7n9mb</td>\n",
       "      <td>2025-09-03 18:45:38+00:00</td>\n",
       "      <td>Ameeeekay</td>\n",
       "      <td>OOTD ü§çüñ§</td>\n",
       "      <td>Fast and Free High-Rise Classic-Fit Split Shor...</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>Fit Pics</td>\n",
       "      <td>https://www.reddit.com/r/lululemon/comments/1n...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1n7n4e1</td>\n",
       "      <td>2025-09-03 18:40:03+00:00</td>\n",
       "      <td>Apprehensive_Place51</td>\n",
       "      <td>insulated os collared jacket sizing</td>\n",
       "      <td>could anyone give me sizing advice on this? i'...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Sizing Advice</td>\n",
       "      <td>https://www.reddit.com/r/lululemon/comments/1n...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id                 timestamp                author  \\\n",
       "0  1n7q2s8 2025-09-03 20:31:13+00:00            berry_pink   \n",
       "1  1n7po2x 2025-09-03 20:16:03+00:00           runandplay2   \n",
       "2  1n7nh4p 2025-09-03 18:53:26+00:00  Puzzleheaded-Fan5586   \n",
       "3  1n7n9mb 2025-09-03 18:45:38+00:00             Ameeeekay   \n",
       "4  1n7n4e1 2025-09-03 18:40:03+00:00  Apprehensive_Place51   \n",
       "\n",
       "                                               title  \\\n",
       "0             Price change in a few days and bad CSR   \n",
       "1  In Store Try On (Rockwood / New define Track t...   \n",
       "2                              Which bag for travel?   \n",
       "3                                            OOTD ü§çüñ§   \n",
       "4                insulated os collared jacket sizing   \n",
       "\n",
       "                                                text  score  num_comments  \\\n",
       "0  I was shopping for a new skirt as a treat-yo-s...      2             0   \n",
       "1  Sorry for the double post today but thought ot...     14             1   \n",
       "2  Looking for a safe crossbody bag for a Europea...      2             2   \n",
       "3  Fast and Free High-Rise Classic-Fit Split Shor...     29             1   \n",
       "4  could anyone give me sizing advice on this? i'...      1             4   \n",
       "\n",
       "                   link_flair_text  \\\n",
       "0                       Discussion   \n",
       "1                         Fit Pics   \n",
       "2  Product Question/Recommendation   \n",
       "3                         Fit Pics   \n",
       "4                    Sizing Advice   \n",
       "\n",
       "                                           permalink stickied locked  \\\n",
       "0  https://www.reddit.com/r/lululemon/comments/1n...    False  False   \n",
       "1  https://www.reddit.com/r/lululemon/comments/1n...    False  False   \n",
       "2  https://www.reddit.com/r/lululemon/comments/1n...    False  False   \n",
       "3  https://www.reddit.com/r/lululemon/comments/1n...    False  False   \n",
       "4  https://www.reddit.com/r/lululemon/comments/1n...    False  False   \n",
       "\n",
       "   upvote_ratio  \n",
       "0          1.00  \n",
       "1          1.00  \n",
       "2          0.75  \n",
       "3          0.89  \n",
       "4          0.66  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Merge with the new posts previously extracted\n",
    "\n",
    "posts_df = (\n",
    "    pd.concat([new_posts_df, posts_df], ignore_index=True)\n",
    "      .drop_duplicates(subset=\"post_id\")\n",
    "      .sort_values(\"timestamp\", ascending=False)\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "examine_df('all posts', posts_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b9ee47-f6d0-4c5c-808f-c10958bd362d",
   "metadata": {},
   "source": [
    "### Extract comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "26a3c616-377e-451d-8fca-9e486a7ea7de",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Number of records in the sample comment dataframe is: 17\n",
      "\n",
      "\n",
      "Number of features in the sample comment dataframe is: 10\n",
      "\n",
      "The columns in the sample comment dataframe are: Index(['post_id', 'comment_id', 'timestamp', 'author', 'body', 'score',\n",
      "       'is_submitter', 'parent_id', 'permalink', 'depth'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      " Other info about sample comment dataframe:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17 entries, 0 to 16\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Non-Null Count  Dtype              \n",
      "---  ------        --------------  -----              \n",
      " 0   post_id       17 non-null     object             \n",
      " 1   comment_id    17 non-null     object             \n",
      " 2   timestamp     17 non-null     datetime64[ns, UTC]\n",
      " 3   author        17 non-null     object             \n",
      " 4   body          17 non-null     object             \n",
      " 5   score         17 non-null     int64              \n",
      " 6   is_submitter  17 non-null     bool               \n",
      " 7   parent_id     17 non-null     object             \n",
      " 8   permalink     17 non-null     object             \n",
      " 9   depth         17 non-null     int64              \n",
      "dtypes: bool(1), datetime64[ns, UTC](1), int64(2), object(6)\n",
      "memory usage: 1.3+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Basic statistical info about sample comment dataframe:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.941176</td>\n",
       "      <td>0.411765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.983387</td>\n",
       "      <td>0.507300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           score      depth\n",
       "count  17.000000  17.000000\n",
       "mean    2.941176   0.411765\n",
       "std     1.983387   0.507300\n",
       "min     1.000000   0.000000\n",
       "25%     1.000000   0.000000\n",
       "50%     2.000000   0.000000\n",
       "75%     4.000000   1.000000\n",
       "max     8.000000   1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Sample of records in the sample comment dataframe:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "      <th>score</th>\n",
       "      <th>is_submitter</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>permalink</th>\n",
       "      <th>depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1n70wil</td>\n",
       "      <td>nc42dzh</td>\n",
       "      <td>2025-09-03 00:49:54+00:00</td>\n",
       "      <td>AutoModerator</td>\n",
       "      <td>Hello! This is a comment to let you know that ...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>t3_1n70wil</td>\n",
       "      <td>https://www.reddit.com/r/lululemon/comments/1n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1n70wil</td>\n",
       "      <td>nc45beg</td>\n",
       "      <td>2025-09-03 01:06:58+00:00</td>\n",
       "      <td>Jimmy_Philly_B-more</td>\n",
       "      <td>Oh wow, absolutely love how this pairs with Ja...</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>t3_1n70wil</td>\n",
       "      <td>https://www.reddit.com/r/lululemon/comments/1n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1n70wil</td>\n",
       "      <td>nc43rfz</td>\n",
       "      <td>2025-09-03 00:57:56+00:00</td>\n",
       "      <td>painthrowaway852</td>\n",
       "      <td>other colors I'm curious to pair with: Sequoia...</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>t3_1n70wil</td>\n",
       "      <td>https://www.reddit.com/r/lululemon/comments/1n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1n70wil</td>\n",
       "      <td>nc4nj9l</td>\n",
       "      <td>2025-09-03 02:56:45+00:00</td>\n",
       "      <td>4merly-chicken</td>\n",
       "      <td>It looks like a colour that will pop with true...</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>t3_1n70wil</td>\n",
       "      <td>https://www.reddit.com/r/lululemon/comments/1n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1n70wil</td>\n",
       "      <td>nc48ifr</td>\n",
       "      <td>2025-09-03 01:25:43+00:00</td>\n",
       "      <td>SpideyWhiplash</td>\n",
       "      <td>Love your pairings!üíØ Always keep me excited ab...</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>t3_1n70wil</td>\n",
       "      <td>https://www.reddit.com/r/lululemon/comments/1n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id comment_id                 timestamp               author  \\\n",
       "0  1n70wil    nc42dzh 2025-09-03 00:49:54+00:00        AutoModerator   \n",
       "1  1n70wil    nc45beg 2025-09-03 01:06:58+00:00  Jimmy_Philly_B-more   \n",
       "2  1n70wil    nc43rfz 2025-09-03 00:57:56+00:00     painthrowaway852   \n",
       "3  1n70wil    nc4nj9l 2025-09-03 02:56:45+00:00       4merly-chicken   \n",
       "4  1n70wil    nc48ifr 2025-09-03 01:25:43+00:00       SpideyWhiplash   \n",
       "\n",
       "                                                body  score  is_submitter  \\\n",
       "0  Hello! This is a comment to let you know that ...      1         False   \n",
       "1  Oh wow, absolutely love how this pairs with Ja...      8         False   \n",
       "2  other colors I'm curious to pair with: Sequoia...      5          True   \n",
       "3  It looks like a colour that will pop with true...      5         False   \n",
       "4  Love your pairings!üíØ Always keep me excited ab...      4         False   \n",
       "\n",
       "    parent_id                                          permalink  depth  \n",
       "0  t3_1n70wil  https://www.reddit.com/r/lululemon/comments/1n...      0  \n",
       "1  t3_1n70wil  https://www.reddit.com/r/lululemon/comments/1n...      0  \n",
       "2  t3_1n70wil  https://www.reddit.com/r/lululemon/comments/1n...      0  \n",
       "3  t3_1n70wil  https://www.reddit.com/r/lululemon/comments/1n...      0  \n",
       "4  t3_1n70wil  https://www.reddit.com/r/lululemon/comments/1n...      0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract dataframe of comments for particular post\n",
    "\n",
    "sample_comments_df = fetch_comments_for_post('1n70wil')\n",
    "\n",
    "examine_df('sample comment dataframe', sample_comments_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1fca421f-2afc-4324-b41d-85d0a873ed88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/1593] Collected 7 comments from post 1mvej12\n",
      "\n",
      "[2/1593] Collected 3 comments from post 1mom9ja\n",
      "\n",
      "[3/1593] Collected 16 comments from post 1n5v2mk\n",
      "\n",
      "[4/1593] Collected 6 comments from post 1ml6jh1\n",
      "\n",
      "[5/1593] Collected 13 comments from post wji4ng\n",
      "\n",
      "[6/1593] Collected 5 comments from post 1gx00sn\n",
      "\n",
      "[7/1593] Collected 2 comments from post 1mufl2e\n",
      "\n",
      "[8/1593] Collected 2 comments from post 1mhttl3\n",
      "\n",
      "[9/1593] Collected 16 comments from post 1g0tr6r\n",
      "\n",
      "[10/1593] Collected 11 comments from post 1ghwx4t\n",
      "\n",
      "[11/1593] Collected 137 comments from post 1f0ej9i\n",
      "\n",
      "[12/1593] Collected 6 comments from post 1n4cutv\n",
      "\n",
      "[13/1593] Collected 273 comments from post 10ahte7\n",
      "\n",
      "[14/1593] Collected 41 comments from post 10hbk75\n",
      "\n",
      "[15/1593] Collected 87 comments from post 1n5xs8x\n",
      "\n",
      "[16/1593] Collected 85 comments from post 1mvw5dh\n",
      "\n",
      "[17/1593] Collected 29 comments from post 12g5ozl\n",
      "\n",
      "[18/1593] Collected 6 comments from post 1msmgde\n",
      "\n",
      "[19/1593] Collected 44 comments from post 1ljbmpt\n",
      "\n",
      "[20/1593] Collected 90 comments from post uz9rbv\n",
      "\n",
      "[21/1593] Collected 6 comments from post 1mtocib\n",
      "\n",
      "[22/1593] Collected 13 comments from post 1mf77kz\n",
      "\n",
      "[23/1593] Collected 3 comments from post 1mik8r5\n",
      "\n",
      "[24/1593] Collected 7 comments from post 1n36v52\n",
      "\n",
      "[25/1593] Collected 34 comments from post 1mey1ld\n",
      "\n",
      "[26/1593] Collected 25 comments from post 1gbd1x4\n",
      "\n",
      "[27/1593] Collected 5 comments from post 1mbcmro\n",
      "\n",
      "[28/1593] Collected 2 comments from post 1mqa68i\n",
      "\n",
      "[29/1593] Collected 22 comments from post 1fz4xc5\n",
      "\n",
      "[30/1593] Collected 95 comments from post 1kv4f2s\n",
      "\n",
      "[31/1593] Collected 6 comments from post 1n0zoya\n",
      "\n",
      "[32/1593] Collected 41 comments from post 1jlc91d\n",
      "\n",
      "[33/1593] Collected 13 comments from post 1mtlfq2\n",
      "\n",
      "[34/1593] Collected 13 comments from post 1fks4h7\n",
      "\n",
      "[35/1593] Collected 23 comments from post 1muslgo\n",
      "\n",
      "[36/1593] Collected 44 comments from post 1fm5mzs\n",
      "\n",
      "[37/1593] Collected 7 comments from post 1n057qn\n",
      "\n",
      "[38/1593] Collected 5 comments from post 1mo4yua\n",
      "\n",
      "[39/1593] Collected 79 comments from post 1besyi3\n",
      "\n",
      "[40/1593] Collected 20 comments from post 1mkg4we\n",
      "\n",
      "[41/1593] Collected 23 comments from post 1n64f64\n",
      "\n",
      "[42/1593] Collected 8 comments from post 1mxscf6\n",
      "\n",
      "[43/1593] Collected 3 comments from post 1mcpkv2\n",
      "\n",
      "[44/1593] Collected 3 comments from post 1n7eggu\n",
      "\n",
      "[45/1593] Collected 10 comments from post 1my120e\n",
      "\n",
      "[46/1593] Collected 53 comments from post w4jtsb\n",
      "\n",
      "[47/1593] Collected 7 comments from post 1mz6gh8\n",
      "\n",
      "[48/1593] Collected 5 comments from post 1mtj1iv\n",
      "\n",
      "[49/1593] Collected 79 comments from post 1kmjwe3\n",
      "\n",
      "[50/1593] Collected 23 comments from post 1mg4zew\n",
      "\n",
      "[51/1593] Collected 33 comments from post 1id2lew\n",
      "\n",
      "[52/1593] Collected 15 comments from post 1mm8i7g\n",
      "\n",
      "[53/1593] Collected 172 comments from post 1jw92b7\n",
      "\n",
      "[54/1593] Collected 7 comments from post 1mk35cj\n",
      "\n",
      "[55/1593] Collected 2 comments from post 1mft76n\n",
      "\n",
      "[56/1593] Collected 26 comments from post u2ertj\n",
      "\n",
      "[57/1593] Collected 3 comments from post 1muwc7c\n",
      "\n",
      "[58/1593] Collected 5 comments from post 1msprxx\n",
      "\n",
      "[59/1593] Collected 7 comments from post 1n14jnt\n",
      "\n",
      "[60/1593] Collected 232 comments from post 17m5r6h\n",
      "\n",
      "[61/1593] Collected 54 comments from post 1fle88n\n",
      "\n",
      "[62/1593] Collected 5 comments from post 1n60v75\n",
      "\n",
      "[63/1593] Collected 17 comments from post 1mt40vh\n",
      "\n",
      "[64/1593] Collected 19 comments from post 1n4loj0\n",
      "\n",
      "[65/1593] Collected 23 comments from post 1h3jght\n",
      "\n",
      "[66/1593] Collected 24 comments from post 1g574dd\n",
      "\n",
      "[67/1593] Collected 10 comments from post 1meyas4\n",
      "\n",
      "[68/1593] Collected 9 comments from post 1mj5u2i\n",
      "\n",
      "[69/1593] Collected 12 comments from post 1mnfoty\n",
      "\n",
      "[70/1593] Collected 9 comments from post 1mvnqcl\n",
      "\n",
      "[71/1593] Collected 7 comments from post 1mazc4q\n",
      "\n",
      "[72/1593] Collected 35 comments from post 1kqqybp\n",
      "\n",
      "[73/1593] Collected 5 comments from post 1n4hvve\n",
      "\n",
      "[74/1593] Collected 69 comments from post 1gc2r6g\n",
      "\n",
      "[75/1593] Collected 57 comments from post 1jz9a7u\n",
      "\n",
      "[76/1593] Collected 25 comments from post 1mj2c5r\n",
      "\n",
      "[77/1593] Collected 46 comments from post 1e4z34j\n",
      "\n",
      "[78/1593] Collected 30 comments from post 1n09pga\n",
      "\n",
      "[79/1593] Collected 11 comments from post 1mapnc2\n",
      "\n",
      "[80/1593] Collected 17 comments from post 1msrxb0\n",
      "\n",
      "[81/1593] Collected 3 comments from post 1mano9n\n",
      "\n",
      "[82/1593] Collected 43 comments from post 1efz71v\n",
      "\n",
      "[83/1593] Collected 26 comments from post 1muqu37\n",
      "\n",
      "[84/1593] Collected 29 comments from post 1l3euv1\n",
      "\n",
      "[85/1593] Collected 2 comments from post 1mt3n5a\n",
      "\n",
      "[86/1593] Collected 17 comments from post 1fns4ou\n",
      "\n",
      "[87/1593] Collected 1 comments from post 1n1yk32\n",
      "\n",
      "[88/1593] Collected 46 comments from post 1moeqvy\n",
      "\n",
      "[89/1593] Collected 163 comments from post 106sriy\n",
      "\n",
      "[90/1593] Collected 5 comments from post 1mgsq0d\n",
      "\n",
      "[91/1593] Collected 20 comments from post 1jvwpmq\n",
      "\n",
      "[92/1593] Collected 117 comments from post 10weos5\n",
      "\n",
      "[93/1593] Collected 13 comments from post 1ma1i4j\n",
      "\n",
      "[94/1593] Collected 36 comments from post u4ayc2\n",
      "\n",
      "[95/1593] Collected 2 comments from post 1mfyqtl\n",
      "\n",
      "[96/1593] Collected 28 comments from post 1ezq97a\n",
      "\n",
      "[97/1593] Collected 34 comments from post y6nv1j\n",
      "\n",
      "[98/1593] Collected 142 comments from post t93ath\n",
      "\n",
      "[99/1593] Collected 24 comments from post 1mv0xwo\n",
      "\n",
      "[100/1593] Collected 31 comments from post 1ggpgfs\n",
      "\n",
      "[101/1593] Collected 74 comments from post u31am6\n",
      "\n",
      "[102/1593] Collected 117 comments from post 16gulko\n",
      "\n",
      "[103/1593] Collected 18 comments from post 12q1dbt\n",
      "\n",
      "[104/1593] Collected 4 comments from post 1my4iqx\n",
      "\n",
      "[105/1593] Collected 18 comments from post 1mp2mhu\n",
      "\n",
      "[106/1593] Collected 31 comments from post 1mwakfx\n",
      "\n",
      "[107/1593] Collected 180 comments from post y5ukmx\n",
      "\n",
      "[108/1593] Collected 45 comments from post 1ipqsgb\n",
      "\n",
      "[109/1593] Collected 3 comments from post 1mfmmu8\n",
      "\n",
      "[110/1593] Collected 88 comments from post 1mtgrw9\n",
      "\n",
      "[111/1593] Collected 15 comments from post 1mmpii8\n",
      "\n",
      "[112/1593] Collected 0 comments from post 1ggzm5g\n",
      "\n",
      "[113/1593] Collected 126 comments from post 14gj7em\n",
      "\n",
      "[114/1593] Collected 14 comments from post 1msslv9\n",
      "\n",
      "[115/1593] Collected 1 comments from post 1mlr4iy\n",
      "\n",
      "[116/1593] Collected 12 comments from post 1mx9neo\n",
      "\n",
      "[117/1593] Collected 18 comments from post 1ml4a4c\n",
      "\n",
      "[118/1593] Collected 4 comments from post 1mfvukz\n",
      "\n",
      "[119/1593] Collected 14 comments from post 1n3sdhz\n",
      "\n",
      "[120/1593] Collected 7 comments from post 1mqc9sm\n",
      "\n",
      "[121/1593] Collected 94 comments from post 1n4egi1\n",
      "\n",
      "[122/1593] Collected 10 comments from post 1ml8g8k\n",
      "\n",
      "[123/1593] Collected 94 comments from post 1akvn0x\n",
      "\n",
      "[124/1593] Collected 48 comments from post 1l5716k\n",
      "\n",
      "[125/1593] Collected 7 comments from post 1mribu4\n",
      "\n",
      "[126/1593] Collected 49 comments from post 1jis288\n",
      "\n",
      "[127/1593] Collected 60 comments from post 1mh8dpa\n",
      "\n",
      "[128/1593] Collected 82 comments from post urxmix\n",
      "\n",
      "[129/1593] Collected 22 comments from post 1n193ew\n",
      "\n",
      "[130/1593] Collected 59 comments from post z4msbe\n",
      "\n",
      "[131/1593] Collected 0 comments from post 1n614p9\n",
      "\n",
      "[132/1593] Collected 66 comments from post 16pfnug\n",
      "\n",
      "[133/1593] Collected 6 comments from post 1n7hde1\n",
      "\n",
      "[134/1593] Collected 19 comments from post 1mv1jic\n",
      "\n",
      "[135/1593] Collected 33 comments from post 1kb87du\n",
      "\n",
      "[136/1593] Collected 5 comments from post 1mf3yyw\n",
      "\n",
      "[137/1593] Collected 4 comments from post 1n1xmvw\n",
      "\n",
      "[138/1593] Collected 33 comments from post 1mxyj9b\n",
      "\n",
      "[139/1593] Collected 38 comments from post sdksxm\n",
      "\n",
      "[140/1593] Collected 412 comments from post 14ljmyr\n",
      "\n",
      "[141/1593] Collected 30 comments from post 1ffxd8x\n",
      "\n",
      "[142/1593] Collected 4 comments from post 1mcogbm\n",
      "\n",
      "[143/1593] Collected 11 comments from post 1my778x\n",
      "\n",
      "[144/1593] Collected 46 comments from post 1lyu2bq\n",
      "\n",
      "[145/1593] Collected 20 comments from post 1n2w4g3\n",
      "\n",
      "[146/1593] Collected 16 comments from post 1mr1wsv\n",
      "\n",
      "[147/1593] Collected 3 comments from post 1mergyh\n",
      "\n",
      "[148/1593] Collected 6 comments from post 1msm0x4\n",
      "\n",
      "[149/1593] Collected 33 comments from post 1e4smud\n",
      "\n",
      "[150/1593] Collected 19 comments from post 1meowfy\n",
      "\n",
      "[151/1593] Collected 4 comments from post 1mygewa\n",
      "\n",
      "[152/1593] Collected 49 comments from post ztlzpp\n",
      "\n",
      "[153/1593] Collected 27 comments from post 1mqj31z\n",
      "\n",
      "[154/1593] Collected 5 comments from post 1mkgl2w\n",
      "\n",
      "[155/1593] Collected 56 comments from post 1mxcdl6\n",
      "\n",
      "[156/1593] Collected 5 comments from post 1gqbdhw\n",
      "\n",
      "[157/1593] Collected 2 comments from post 1mxe6ey\n",
      "\n",
      "[158/1593] Collected 28 comments from post 1f1pmc6\n",
      "\n",
      "[159/1593] Collected 74 comments from post 1gb64zh\n",
      "\n",
      "[160/1593] Collected 25 comments from post 1mqdwph\n",
      "\n",
      "[161/1593] Collected 49 comments from post 1cwrd1b\n",
      "\n",
      "[162/1593] Collected 39 comments from post 11gzy45\n",
      "\n",
      "[163/1593] Collected 3 comments from post 1mun7x7\n",
      "\n",
      "[164/1593] Collected 15 comments from post 1mz5p53\n",
      "\n",
      "[165/1593] Collected 9 comments from post 1mxib3e\n",
      "\n",
      "[166/1593] Collected 43 comments from post 12s52c7\n",
      "\n",
      "[167/1593] Collected 44 comments from post 1mdmpp3\n",
      "\n",
      "[168/1593] Collected 6 comments from post 1mhg5cu\n",
      "\n",
      "[169/1593] Collected 29 comments from post 1gvw5ag\n",
      "\n",
      "[170/1593] Collected 2 comments from post 1mobku2\n",
      "\n",
      "[171/1593] Collected 18 comments from post 1mwcusw\n",
      "\n",
      "[172/1593] Collected 5 comments from post 1n00hce\n",
      "\n",
      "[173/1593] Collected 41 comments from post 1iu2lw0\n",
      "\n",
      "[174/1593] Collected 27 comments from post 1gpwcaj\n",
      "\n",
      "[175/1593] Collected 39 comments from post 1gjrqkp\n",
      "\n",
      "[176/1593] Collected 2 comments from post 1mtq9by\n",
      "\n",
      "[177/1593] Collected 60 comments from post 1mf8i0a\n",
      "\n",
      "[178/1593] Collected 12 comments from post 1mspcpn\n",
      "\n",
      "[179/1593] Collected 22 comments from post 1ll9vdl\n",
      "\n",
      "[180/1593] Collected 28 comments from post zvo2lp\n",
      "\n",
      "[181/1593] Collected 1 comments from post 1n4y25p\n",
      "\n",
      "[182/1593] Collected 41 comments from post 1gbdmqc\n",
      "\n",
      "[183/1593] Collected 50 comments from post 1gs22e3\n",
      "\n",
      "[184/1593] Collected 3 comments from post 1mmptjh\n",
      "\n",
      "[185/1593] Collected 9 comments from post 1mg2l26\n",
      "\n",
      "[186/1593] Collected 11 comments from post 1mvz1rl\n",
      "\n",
      "[187/1593] Collected 217 comments from post tho295\n",
      "\n",
      "[188/1593] Collected 35 comments from post 1jaduhq\n",
      "\n",
      "[189/1593] Collected 15 comments from post 1mgc2vd\n",
      "\n",
      "[190/1593] Collected 5 comments from post 1mvc8e3\n",
      "\n",
      "[191/1593] Collected 97 comments from post 1mbs3cj\n",
      "\n",
      "[192/1593] Collected 10 comments from post 1muyd99\n",
      "\n",
      "[193/1593] Collected 10 comments from post 1ms595t\n",
      "\n",
      "[194/1593] Collected 26 comments from post 1h4e8x4\n",
      "\n",
      "[195/1593] Collected 226 comments from post 1c12f41\n",
      "\n",
      "[196/1593] Collected 5 comments from post 1mxg45r\n",
      "\n",
      "[197/1593] Collected 217 comments from post xr8s1j\n",
      "\n",
      "[198/1593] Collected 10 comments from post 1mt2x94\n",
      "\n",
      "[199/1593] Collected 14 comments from post 1n1vsrm\n",
      "\n",
      "[200/1593] Collected 14 comments from post 1gwzxmz\n",
      "\n",
      "[201/1593] Collected 263 comments from post 1gevtqa\n",
      "\n",
      "[202/1593] Collected 8 comments from post 1n5uesy\n",
      "\n",
      "[203/1593] Collected 8 comments from post 1n6jmaa\n",
      "\n",
      "[204/1593] Collected 10 comments from post 1mgrcf3\n",
      "\n",
      "[205/1593] Collected 7 comments from post 1gxdbe0\n",
      "\n",
      "[206/1593] Collected 58 comments from post 1iov9lz\n",
      "\n",
      "[207/1593] Collected 41 comments from post 10snocm\n",
      "\n",
      "[208/1593] Collected 15 comments from post 1mum6ja\n",
      "\n",
      "[209/1593] Collected 25 comments from post 1fxg45i\n",
      "\n",
      "[210/1593] Collected 6 comments from post 1mesqkv\n",
      "\n",
      "[211/1593] Collected 3 comments from post 1mimbzg\n",
      "\n",
      "[212/1593] Collected 18 comments from post 1mgjt6w\n",
      "\n",
      "[213/1593] Collected 1 comments from post 1n4vqks\n",
      "\n",
      "[214/1593] Collected 43 comments from post zki6lo\n",
      "\n",
      "[215/1593] Collected 12 comments from post 1n1q1c4\n",
      "\n",
      "[216/1593] Collected 16 comments from post 1mse7au\n",
      "\n",
      "[217/1593] Collected 6 comments from post 1muinvw\n",
      "\n",
      "[218/1593] Collected 2 comments from post 1mbu1i4\n",
      "\n",
      "[219/1593] Collected 22 comments from post vv9lwe\n",
      "\n",
      "[220/1593] Collected 6 comments from post 1n1xc15\n",
      "\n",
      "[221/1593] Collected 319 comments from post 1di6k31\n",
      "\n",
      "[222/1593] Collected 3 comments from post 1grzarm\n",
      "\n",
      "[223/1593] Collected 10 comments from post 1mwjtex\n",
      "\n",
      "[224/1593] Collected 7 comments from post 1mhxij2\n",
      "\n",
      "[225/1593] Collected 6 comments from post 1mpwvt7\n",
      "\n",
      "[226/1593] Collected 18 comments from post 1n15bzq\n",
      "\n",
      "[227/1593] Collected 3 comments from post 1mhy4kr\n",
      "\n",
      "[228/1593] Collected 75 comments from post 1mqtawr\n",
      "\n",
      "[229/1593] Collected 19 comments from post 1n0m0kr\n",
      "\n",
      "[230/1593] Collected 210 comments from post 1glmga7\n",
      "\n",
      "[231/1593] Collected 139 comments from post xfyp9z\n",
      "\n",
      "[232/1593] Collected 21 comments from post 1mogfkp\n",
      "\n",
      "[233/1593] Collected 124 comments from post 1hry1jb\n",
      "\n",
      "[234/1593] Collected 9 comments from post 1mn7slp\n",
      "\n",
      "[235/1593] Collected 15 comments from post 1mfvfuz\n",
      "\n",
      "[236/1593] Collected 4 comments from post 1mayeud\n",
      "\n",
      "[237/1593] Collected 11 comments from post 1mlp58h\n",
      "\n",
      "[238/1593] Collected 103 comments from post 153lkjm\n",
      "\n",
      "[239/1593] Collected 26 comments from post 1fxqx6f\n",
      "\n",
      "[240/1593] Collected 6 comments from post 1mwe325\n",
      "\n",
      "[241/1593] Collected 5 comments from post 1mgi0fc\n",
      "\n",
      "[242/1593] Collected 12 comments from post 1n5po3l\n",
      "\n",
      "[243/1593] Collected 88 comments from post 14iq9sx\n",
      "\n",
      "[244/1593] Collected 61 comments from post 1965hvw\n",
      "\n",
      "[245/1593] Collected 10 comments from post 1n1okl2\n",
      "\n",
      "[246/1593] Collected 3 comments from post 1mtcl1u\n",
      "\n",
      "[247/1593] Collected 11 comments from post 1mpzpfj\n",
      "\n",
      "[248/1593] Collected 1 comments from post 1mc8rrq\n",
      "\n",
      "[249/1593] Collected 319 comments from post 1dly2jz\n",
      "\n",
      "[250/1593] Collected 19 comments from post 1gmklhh\n",
      "\n",
      "[251/1593] Collected 104 comments from post 1mjs7jp\n",
      "\n",
      "[252/1593] Collected 244 comments from post 1mi43co\n",
      "\n",
      "[253/1593] Collected 69 comments from post 1hcmwz8\n",
      "\n",
      "[254/1593] Collected 145 comments from post 1fqxz95\n",
      "\n",
      "[255/1593] Collected 98 comments from post znoan3\n",
      "\n",
      "[256/1593] Collected 4 comments from post 1mz73is\n",
      "\n",
      "[257/1593] Collected 4 comments from post 1mkened\n",
      "\n",
      "[258/1593] Collected 28 comments from post 1mozb5l\n",
      "\n",
      "[259/1593] Collected 18 comments from post 1mqu7u9\n",
      "\n",
      "[260/1593] Collected 23 comments from post 1gsuc7y\n",
      "\n",
      "[261/1593] Collected 20 comments from post 1mhrjyn\n",
      "\n",
      "[262/1593] Collected 4 comments from post 1ms3ye9\n",
      "\n",
      "[263/1593] Collected 14 comments from post 1mzwu42\n",
      "\n",
      "[264/1593] Collected 4 comments from post 1mkfftu\n",
      "\n",
      "[265/1593] Collected 41 comments from post 1mxenio\n",
      "\n",
      "[266/1593] Collected 20 comments from post 1n3wwl4\n",
      "\n",
      "[267/1593] Collected 44 comments from post 1g9r1je\n",
      "\n",
      "[268/1593] Collected 4 comments from post 1mp0oe7\n",
      "\n",
      "[269/1593] Collected 53 comments from post 1gschht\n",
      "\n",
      "[270/1593] Collected 84 comments from post 1n6hyb8\n",
      "\n",
      "[271/1593] Collected 14 comments from post 1me7yrv\n",
      "\n",
      "[272/1593] Collected 2 comments from post 1map3n2\n",
      "\n",
      "[273/1593] Collected 15 comments from post 1mzp498\n",
      "\n",
      "[274/1593] Collected 13 comments from post 1mq5n5h\n",
      "\n",
      "[275/1593] Collected 1 comments from post 1mx7rrb\n",
      "\n",
      "[276/1593] Collected 8 comments from post 1n4hjn8\n",
      "\n",
      "[277/1593] Collected 2 comments from post 1gfuyx3\n",
      "\n",
      "[278/1593] Collected 8 comments from post 1mswo7c\n",
      "\n",
      "[279/1593] Collected 4 comments from post 1mhrpee\n",
      "\n",
      "[280/1593] Collected 49 comments from post 1gkbwym\n",
      "\n",
      "[281/1593] Collected 12 comments from post 1gb2uge\n",
      "\n",
      "[282/1593] Collected 6 comments from post 1md8o9k\n",
      "\n",
      "[283/1593] Collected 20 comments from post 1mmzo2n\n",
      "\n",
      "[284/1593] Collected 20 comments from post 1mufwrz\n",
      "\n",
      "[285/1593] Collected 8 comments from post 1n7lcwh\n",
      "\n",
      "[286/1593] Collected 18 comments from post 1ma0i3l\n",
      "\n",
      "[287/1593] Collected 270 comments from post 1crdg4m\n",
      "\n",
      "[288/1593] Collected 51 comments from post 1gcmxbc\n",
      "\n",
      "[289/1593] Collected 9 comments from post 1mpnu6p\n",
      "\n",
      "[290/1593] Collected 17 comments from post 1meh8ny\n",
      "\n",
      "[291/1593] Collected 50 comments from post 1mnm0u7\n",
      "\n",
      "[292/1593] Collected 7 comments from post 1n65mqu\n",
      "\n",
      "[293/1593] Collected 3 comments from post 1mp67m4\n",
      "\n",
      "[294/1593] Collected 73 comments from post 1mtzpr3\n",
      "\n",
      "[295/1593] Collected 76 comments from post 131rl5x\n",
      "\n",
      "[296/1593] Collected 1 comments from post 1mhdzvb\n",
      "\n",
      "[297/1593] Collected 29 comments from post 1me3air\n",
      "\n",
      "[298/1593] Collected 3 comments from post 1gk5rnb\n",
      "\n",
      "[299/1593] Collected 17 comments from post 1fxexv5\n",
      "\n",
      "[300/1593] Collected 15 comments from post 1mpzgtr\n",
      "\n",
      "[301/1593] Collected 3 comments from post 1mamikz\n",
      "\n",
      "[302/1593] Collected 0 comments from post 1mobh27\n",
      "\n",
      "[303/1593] Collected 9 comments from post 1md95e1\n",
      "\n",
      "[304/1593] Collected 30 comments from post 1ml83w6\n",
      "\n",
      "[305/1593] Collected 45 comments from post 1mim2k9\n",
      "\n",
      "[306/1593] Collected 46 comments from post txcca9\n",
      "\n",
      "[307/1593] Collected 9 comments from post 1n0lfb8\n",
      "\n",
      "[308/1593] Collected 13 comments from post 1gb06l7\n",
      "\n",
      "[309/1593] Collected 57 comments from post 1g7d447\n",
      "\n",
      "[310/1593] Collected 40 comments from post 1gv1epg\n",
      "\n",
      "[311/1593] Collected 105 comments from post y35oyo\n",
      "\n",
      "[312/1593] Collected 60 comments from post uw11xz\n",
      "\n",
      "[313/1593] Collected 5 comments from post 1mvlcv2\n",
      "\n",
      "[314/1593] Collected 4 comments from post 1n39f9b\n",
      "\n",
      "[315/1593] Collected 128 comments from post 1agq4cq\n",
      "\n",
      "[316/1593] Collected 15 comments from post 14b9ewp\n",
      "\n",
      "[317/1593] Collected 13 comments from post 1n7kykk\n",
      "\n",
      "[318/1593] Collected 11 comments from post 1msu9z2\n",
      "\n",
      "[319/1593] Collected 74 comments from post zg2eq2\n",
      "\n",
      "[320/1593] Collected 11 comments from post 1n7fyzg\n",
      "\n",
      "[321/1593] Collected 0 comments from post 1mgxbqu\n",
      "\n",
      "[322/1593] Collected 31 comments from post 1btcgq0\n",
      "\n",
      "[323/1593] Collected 53 comments from post 1fnq42s\n",
      "\n",
      "[324/1593] Collected 4 comments from post 1mwel4i\n",
      "\n",
      "[325/1593] Collected 12 comments from post 1n5r1jf\n",
      "\n",
      "[326/1593] Collected 5 comments from post 1n5liw2\n",
      "\n",
      "[327/1593] Collected 151 comments from post 1ajagai\n",
      "\n",
      "[328/1593] Collected 182 comments from post siq2me\n",
      "\n",
      "[329/1593] Collected 42 comments from post 1cex0yf\n",
      "\n",
      "[330/1593] Collected 50 comments from post 1n4y4hf\n",
      "\n",
      "[331/1593] Collected 14 comments from post 1io7ao2\n",
      "\n",
      "[332/1593] Collected 28 comments from post 1mjcjlw\n",
      "\n",
      "[333/1593] Collected 33 comments from post w3m82a\n",
      "\n",
      "[334/1593] Collected 8 comments from post 1mua1or\n",
      "\n",
      "[335/1593] Collected 51 comments from post 1jrzefh\n",
      "\n",
      "[336/1593] Collected 16 comments from post 1n17rnb\n",
      "\n",
      "[337/1593] Collected 43 comments from post 1iii1bg\n",
      "\n",
      "[338/1593] Collected 7 comments from post 1n2salj\n",
      "\n",
      "[339/1593] Collected 0 comments from post 1meiixa\n",
      "\n",
      "[340/1593] Collected 15 comments from post 1gsptn8\n",
      "\n",
      "[341/1593] Collected 9 comments from post 1g9iawh\n",
      "\n",
      "[342/1593] Collected 37 comments from post 1mojp2m\n",
      "\n",
      "[343/1593] Collected 7 comments from post 1mo7fu6\n",
      "\n",
      "[344/1593] Collected 1 comments from post 1mnwx91\n",
      "\n",
      "[345/1593] Collected 43 comments from post 189y2qq\n",
      "\n",
      "[346/1593] Collected 0 comments from post 1n6jsco\n",
      "\n",
      "[347/1593] Collected 8 comments from post 1mvyksp\n",
      "\n",
      "[348/1593] Collected 6 comments from post 1mqn6wm\n",
      "\n",
      "[349/1593] Collected 7 comments from post 1mnc0z2\n",
      "\n",
      "[350/1593] Collected 76 comments from post 1mq23h9\n",
      "\n",
      "[351/1593] Collected 6 comments from post 1n4pxyu\n",
      "\n",
      "[352/1593] Collected 8 comments from post 1mun0gq\n",
      "\n",
      "[353/1593] Collected 74 comments from post 13iwspm\n",
      "\n",
      "[354/1593] Collected 17 comments from post 1f8wiwn\n",
      "\n",
      "[355/1593] Collected 43 comments from post 16m4sg4\n",
      "\n",
      "[356/1593] Collected 28 comments from post 1mujdhp\n",
      "\n",
      "[357/1593] Collected 34 comments from post 1bantro\n",
      "\n",
      "[358/1593] Collected 32 comments from post w215d4\n",
      "\n",
      "[359/1593] Collected 7 comments from post 1mugo50\n",
      "\n",
      "[360/1593] Collected 6 comments from post 1n5gqu2\n",
      "\n",
      "[361/1593] Collected 13 comments from post 1mr6t18\n",
      "\n",
      "[362/1593] Collected 184 comments from post vhyavn\n",
      "\n",
      "[363/1593] Collected 119 comments from post 1c00c51\n",
      "\n",
      "[364/1593] Collected 37 comments from post 1mca19s\n",
      "\n",
      "[365/1593] Collected 39 comments from post 11jgj0v\n",
      "\n",
      "[366/1593] Collected 41 comments from post x6gaus\n",
      "\n",
      "[367/1593] Collected 26 comments from post ulc8wl\n",
      "\n",
      "[368/1593] Collected 41 comments from post 1fvbox6\n",
      "\n",
      "[369/1593] Collected 37 comments from post 18plpis\n",
      "\n",
      "[370/1593] Collected 21 comments from post 1n6407b\n",
      "\n",
      "[371/1593] Collected 36 comments from post 1hpvs7b\n",
      "\n",
      "[372/1593] Collected 8 comments from post 1n0yzc9\n",
      "\n",
      "[373/1593] Collected 56 comments from post 1c5tl7p\n",
      "\n",
      "[374/1593] Collected 14 comments from post 1mnxvnh\n",
      "\n",
      "[375/1593] Collected 8 comments from post 1mvojji\n",
      "\n",
      "[376/1593] Collected 26 comments from post 1mkd8tt\n",
      "\n",
      "[377/1593] Collected 5 comments from post 1mzv9cn\n",
      "\n",
      "[378/1593] Collected 1 comments from post 1mgl0mu\n",
      "\n",
      "[379/1593] Collected 5 comments from post 1mfvoym\n",
      "\n",
      "[380/1593] Collected 31 comments from post rzkiww\n",
      "\n",
      "[381/1593] Collected 1 comments from post 1mlcwg2\n",
      "\n",
      "[382/1593] Collected 1 comments from post 1mvx775\n",
      "\n",
      "[383/1593] Collected 189 comments from post 1hvb91q\n",
      "\n",
      "[384/1593] Collected 3 comments from post 1mfggv6\n",
      "\n",
      "[385/1593] Collected 37 comments from post 17loa02\n",
      "\n",
      "[386/1593] Collected 126 comments from post 1382rlo\n",
      "\n",
      "[387/1593] Collected 20 comments from post 1fw9u12\n",
      "\n",
      "[388/1593] Collected 12 comments from post 1mgoib2\n",
      "\n",
      "[389/1593] Collected 64 comments from post sst1mh\n",
      "\n",
      "[390/1593] Collected 50 comments from post 1ek5ybe\n",
      "\n",
      "[391/1593] Collected 20 comments from post 1n2p1z9\n",
      "\n",
      "[392/1593] Collected 12 comments from post 1mmo081\n",
      "\n",
      "[393/1593] Collected 44 comments from post 1krlcjf\n",
      "\n",
      "[394/1593] Collected 49 comments from post 1gisf6y\n",
      "\n",
      "[395/1593] Collected 39 comments from post 1bgynaw\n",
      "\n",
      "[396/1593] Collected 2 comments from post 1mqbasx\n",
      "\n",
      "[397/1593] Collected 11 comments from post 1mbcbwy\n",
      "\n",
      "[398/1593] Collected 4 comments from post 1mluyot\n",
      "\n",
      "[399/1593] Collected 34 comments from post 1mvip2v\n",
      "\n",
      "[400/1593] Collected 114 comments from post 19fez4i\n",
      "\n",
      "[401/1593] Collected 11 comments from post 1mlthte\n",
      "\n",
      "[402/1593] Collected 59 comments from post 1f3n4wv\n",
      "\n",
      "[403/1593] Collected 28 comments from post 1mr4mhj\n",
      "\n",
      "[404/1593] Collected 11 comments from post 1miuks6\n",
      "\n",
      "[405/1593] Collected 4 comments from post 1mvy3gm\n",
      "\n",
      "[406/1593] Collected 24 comments from post 1mm6kwa\n",
      "\n",
      "[407/1593] Collected 2 comments from post 1myqo6w\n",
      "\n",
      "[408/1593] Collected 6 comments from post 1n04e5i\n",
      "\n",
      "[409/1593] Collected 20 comments from post 1n42frv\n",
      "\n",
      "[410/1593] Collected 32 comments from post 1mf9jyl\n",
      "\n",
      "[411/1593] Collected 79 comments from post t5xnjq\n",
      "\n",
      "[412/1593] Collected 8 comments from post 1my88rt\n",
      "\n",
      "[413/1593] Collected 2 comments from post 1n6pqir\n",
      "\n",
      "[414/1593] Collected 5 comments from post 1n5bzu2\n",
      "\n",
      "[415/1593] Collected 20 comments from post 1mrel55\n",
      "\n",
      "[416/1593] Collected 22 comments from post 1n35tci\n",
      "\n",
      "[417/1593] Collected 3 comments from post 1mxckcw\n",
      "\n",
      "[418/1593] Collected 120 comments from post 14ckkdy\n",
      "\n",
      "[419/1593] Collected 24 comments from post 1n1b6h7\n",
      "\n",
      "[420/1593] Collected 5 comments from post 1mwapm6\n",
      "\n",
      "[421/1593] Collected 32 comments from post 1mbh5e1\n",
      "\n",
      "[422/1593] Collected 16 comments from post 1n129v5\n",
      "\n",
      "[423/1593] Collected 21 comments from post 1maqpm8\n",
      "\n",
      "[424/1593] Collected 119 comments from post 1cwojo1\n",
      "\n",
      "[425/1593] Collected 29 comments from post 1fpxcb0\n",
      "\n",
      "[426/1593] Collected 25 comments from post 1ma9fi9\n",
      "\n",
      "[427/1593] Collected 78 comments from post 1dpw462\n",
      "\n",
      "[428/1593] Collected 5 comments from post 1migzlh\n",
      "\n",
      "[429/1593] Collected 29 comments from post 1itcudi\n",
      "\n",
      "[430/1593] Collected 10 comments from post 1mnhfsk\n",
      "\n",
      "[431/1593] Collected 13 comments from post 1mk6ko2\n",
      "\n",
      "[432/1593] Collected 46 comments from post 1emkchp\n",
      "\n",
      "[433/1593] Collected 36 comments from post 1n1u8el\n",
      "\n",
      "[434/1593] Collected 57 comments from post 1dg8lbx\n",
      "\n",
      "[435/1593] Collected 164 comments from post 1n6egvw\n",
      "\n",
      "[436/1593] Collected 2 comments from post 1mwz746\n",
      "\n",
      "[437/1593] Collected 193 comments from post 1e2k36f\n",
      "\n",
      "[438/1593] Collected 33 comments from post 1ism43m\n",
      "\n",
      "[439/1593] Collected 3 comments from post 1mi9lh2\n",
      "\n",
      "[440/1593] Collected 14 comments from post 1mbx7hg\n",
      "\n",
      "[441/1593] Collected 5 comments from post 1ma6hor\n",
      "\n",
      "[442/1593] Collected 41 comments from post 19fko11\n",
      "\n",
      "[443/1593] Collected 72 comments from post 1blwq9y\n",
      "\n",
      "[444/1593] Collected 4 comments from post 1mq7aik\n",
      "\n",
      "[445/1593] Collected 9 comments from post 1mmmz23\n",
      "\n",
      "[446/1593] Collected 32 comments from post 1mcdsf6\n",
      "\n",
      "[447/1593] Collected 93 comments from post y0pt9b\n",
      "\n",
      "[448/1593] Collected 0 comments from post 1n0omek\n",
      "\n",
      "[449/1593] Collected 8 comments from post 1ms6qbl\n",
      "\n",
      "[450/1593] Collected 43 comments from post 1kq8kof\n",
      "\n",
      "[451/1593] Collected 41 comments from post 1fcbodp\n",
      "\n",
      "[452/1593] Collected 25 comments from post yuiy79\n",
      "\n",
      "[453/1593] Collected 4 comments from post 1n024js\n",
      "\n",
      "[454/1593] Collected 9 comments from post 1n1dpo4\n",
      "\n",
      "[455/1593] Collected 71 comments from post 13jck99\n",
      "\n",
      "[456/1593] Collected 50 comments from post 10xbzzs\n",
      "\n",
      "[457/1593] Collected 23 comments from post 1mpxjse\n",
      "\n",
      "[458/1593] Collected 92 comments from post vkh57t\n",
      "\n",
      "[459/1593] Collected 0 comments from post 1n1vm66\n",
      "\n",
      "[460/1593] Collected 32 comments from post 1mii9sz\n",
      "\n",
      "[461/1593] Collected 160 comments from post w29uxe\n",
      "\n",
      "[462/1593] Collected 37 comments from post 1k0sh5h\n",
      "\n",
      "[463/1593] Collected 14 comments from post 1mrz0xb\n",
      "\n",
      "[464/1593] Collected 16 comments from post 1mw9eqt\n",
      "\n",
      "[465/1593] Collected 79 comments from post 1fcnqqr\n",
      "\n",
      "[466/1593] Collected 43 comments from post 1h88q8k\n",
      "\n",
      "[467/1593] Collected 4 comments from post 1meg17a\n",
      "\n",
      "[468/1593] Collected 26 comments from post 1g013w9\n",
      "\n",
      "[469/1593] Collected 8 comments from post 1gzipxi\n",
      "\n",
      "[470/1593] Collected 42 comments from post 1g200be\n",
      "\n",
      "[471/1593] Collected 11 comments from post 1mtsysq\n",
      "\n",
      "[472/1593] Collected 9 comments from post 1n6klgn\n",
      "\n",
      "[473/1593] Collected 63 comments from post 1mh8dpt\n",
      "\n",
      "[474/1593] Collected 0 comments from post 1mbvwm2\n",
      "\n",
      "[475/1593] Collected 13 comments from post 1n1z2vy\n",
      "\n",
      "[476/1593] Collected 15 comments from post 1mkexpm\n",
      "\n",
      "[477/1593] Collected 4 comments from post 1ma96jj\n",
      "\n",
      "[478/1593] Collected 25 comments from post 1n35t7e\n",
      "\n",
      "[479/1593] Collected 14 comments from post 1mfx0cp\n",
      "\n",
      "[480/1593] Collected 2 comments from post 1my6y8e\n",
      "\n",
      "[481/1593] Collected 2 comments from post 1mxlpkm\n",
      "\n",
      "[482/1593] Collected 2 comments from post 1n1mezn\n",
      "\n",
      "[483/1593] Collected 4 comments from post 1mw2y31\n",
      "\n",
      "[484/1593] Collected 20 comments from post 1mawvu1\n",
      "\n",
      "[485/1593] Collected 4 comments from post 1msti0b\n",
      "\n",
      "[486/1593] Collected 19 comments from post 1n2ajho\n",
      "\n",
      "[487/1593] Collected 16 comments from post 1mhux6f\n",
      "\n",
      "[488/1593] Collected 23 comments from post 1n70wil\n",
      "\n",
      "[489/1593] Collected 15 comments from post 1mw4fhh\n",
      "\n",
      "[490/1593] Collected 47 comments from post 16a1igr\n",
      "\n",
      "[491/1593] Collected 178 comments from post w31rwd\n",
      "\n",
      "[492/1593] Collected 7 comments from post 1mdfkb3\n",
      "\n",
      "[493/1593] Collected 15 comments from post 1mjhb8x\n",
      "\n",
      "[494/1593] Collected 310 comments from post 1fq2qjr\n",
      "\n",
      "[495/1593] Collected 3 comments from post 1n2iadq\n",
      "\n",
      "[496/1593] Collected 20 comments from post 1c5nrf5\n",
      "\n",
      "[497/1593] Collected 12 comments from post 1mikmyh\n",
      "\n",
      "[498/1593] Collected 5 comments from post 1n2li39\n",
      "\n",
      "[499/1593] Collected 40 comments from post xqtybh\n",
      "\n",
      "[500/1593] Collected 5 comments from post 1gu3emq\n",
      "\n",
      "[501/1593] Collected 154 comments from post 13b6zoj\n",
      "\n",
      "[502/1593] Collected 18 comments from post 1n0kwwk\n",
      "\n",
      "[503/1593] Collected 22 comments from post 1me8qts\n",
      "\n",
      "[504/1593] Collected 9 comments from post 1mg7k4k\n",
      "\n",
      "[505/1593] Collected 33 comments from post 1bflf69\n",
      "\n",
      "[506/1593] Collected 2 comments from post 1miazhs\n",
      "\n",
      "[507/1593] Collected 57 comments from post 1g0sxl3\n",
      "\n",
      "[508/1593] Collected 6 comments from post 1mv4kqe\n",
      "\n",
      "[509/1593] Collected 27 comments from post 1ipjhh4\n",
      "\n",
      "[510/1593] Collected 36 comments from post 1fgyf9h\n",
      "\n",
      "[511/1593] Collected 48 comments from post 1dz29l8\n",
      "\n",
      "[512/1593] Collected 22 comments from post 1mut4ff\n",
      "\n",
      "[513/1593] Collected 5 comments from post 1mtvd08\n",
      "\n",
      "[514/1593] Collected 10 comments from post 1mp8ubd\n",
      "\n",
      "[515/1593] Collected 5 comments from post 1md4cze\n",
      "\n",
      "[516/1593] Collected 103 comments from post 1mpsbe8\n",
      "\n",
      "[517/1593] Collected 90 comments from post 1ilhzw3\n",
      "\n",
      "[518/1593] Collected 72 comments from post vnk4ug\n",
      "\n",
      "[519/1593] Collected 38 comments from post 1gpkjf3\n",
      "\n",
      "[520/1593] Collected 4 comments from post 1my29xi\n",
      "\n",
      "[521/1593] Collected 2 comments from post 1mktb4q\n",
      "\n",
      "[522/1593] Collected 22 comments from post 1n4pio3\n",
      "\n",
      "[523/1593] Collected 2 comments from post 1mmrof9\n",
      "\n",
      "[524/1593] Collected 21 comments from post 1mm10k0\n",
      "\n",
      "[525/1593] Collected 5 comments from post 1gil5md\n",
      "\n",
      "[526/1593] Collected 5 comments from post 1mj66iv\n",
      "\n",
      "[527/1593] Collected 3 comments from post 1meh31i\n",
      "\n",
      "[528/1593] Collected 60 comments from post 10ugmvk\n",
      "\n",
      "[529/1593] Collected 2 comments from post 1n5uhb8\n",
      "\n",
      "[530/1593] Collected 54 comments from post 1aub3q9\n",
      "\n",
      "[531/1593] Collected 6 comments from post 1mb92i3\n",
      "\n",
      "[532/1593] Collected 22 comments from post 1msu1fq\n",
      "\n",
      "[533/1593] Collected 12 comments from post 1mchew2\n",
      "\n",
      "[534/1593] Collected 31 comments from post 1n0qth3\n",
      "\n",
      "[535/1593] Collected 27 comments from post 1iq9wm8\n",
      "\n",
      "[536/1593] Collected 99 comments from post 1mnqkg9\n",
      "\n",
      "[537/1593] Collected 41 comments from post 1hxgn48\n",
      "\n",
      "[538/1593] Collected 2 comments from post 1mbty64\n",
      "\n",
      "[539/1593] Collected 18 comments from post 1mlywkh\n",
      "\n",
      "[540/1593] Collected 27 comments from post tv1ggm\n",
      "\n",
      "[541/1593] Collected 128 comments from post 1cbkeg0\n",
      "\n",
      "[542/1593] Collected 1 comments from post 1moembv\n",
      "\n",
      "[543/1593] Collected 13 comments from post 1mtoy3t\n",
      "\n",
      "[544/1593] Collected 15 comments from post 1gfdtny\n",
      "\n",
      "[545/1593] Collected 163 comments from post 192nx12\n",
      "\n",
      "[546/1593] Collected 37 comments from post 1mfly40\n",
      "\n",
      "[547/1593] Collected 63 comments from post 1hf8ym5\n",
      "\n",
      "[548/1593] Collected 42 comments from post 1g85272\n",
      "\n",
      "[549/1593] Collected 32 comments from post 1gj0v79\n",
      "\n",
      "[550/1593] Collected 17 comments from post 1myw33q\n",
      "\n",
      "[551/1593] Collected 2 comments from post 1n1l9fs\n",
      "\n",
      "[552/1593] Collected 31 comments from post 1mqw8kp\n",
      "\n",
      "[553/1593] Collected 6 comments from post 1mxpafc\n",
      "\n",
      "[554/1593] Collected 3 comments from post 1mi8f5z\n",
      "\n",
      "[555/1593] Collected 107 comments from post xxis9h\n",
      "\n",
      "[556/1593] Collected 36 comments from post vdc832\n",
      "\n",
      "[557/1593] Collected 21 comments from post 1n0lloc\n",
      "\n",
      "[558/1593] Collected 109 comments from post 1mduvpe\n",
      "\n",
      "[559/1593] Collected 6 comments from post 1mlpgxw\n",
      "\n",
      "[560/1593] Collected 140 comments from post 1hwcbpy\n",
      "\n",
      "[561/1593] Collected 36 comments from post 1gwplpz\n",
      "\n",
      "[562/1593] Collected 10 comments from post 1my361t\n",
      "\n",
      "[563/1593] Collected 0 comments from post 1mkq79y\n",
      "\n",
      "[564/1593] Collected 13 comments from post 1giyr5r\n",
      "\n",
      "[565/1593] Collected 65 comments from post tyor3q\n",
      "\n",
      "[566/1593] Collected 9 comments from post 1mg0pg0\n",
      "\n",
      "[567/1593] Collected 33 comments from post spm9bo\n",
      "\n",
      "[568/1593] Collected 33 comments from post 1mefw26\n",
      "\n",
      "[569/1593] Collected 9 comments from post 1n4f6cr\n",
      "\n",
      "[570/1593] Collected 25 comments from post 1mwiroa\n",
      "\n",
      "[571/1593] Collected 7 comments from post 1mqa0ju\n",
      "\n",
      "[572/1593] Collected 40 comments from post 1g8ubx3\n",
      "\n",
      "[573/1593] Collected 150 comments from post 1cmmsge\n",
      "\n",
      "[574/1593] Collected 16 comments from post 1mkyw3e\n",
      "\n",
      "[575/1593] Collected 8 comments from post 1mgs741\n",
      "\n",
      "[576/1593] Collected 4 comments from post 1n01wsk\n",
      "\n",
      "[577/1593] Collected 38 comments from post 1mdjep9\n",
      "\n",
      "[578/1593] Collected 19 comments from post 1m9wtmx\n",
      "\n",
      "[579/1593] Collected 12 comments from post 1myg2gx\n",
      "\n",
      "[580/1593] Collected 3 comments from post 1muffza\n",
      "\n",
      "[581/1593] Collected 12 comments from post 1mw0uiu\n",
      "\n",
      "[582/1593] Collected 13 comments from post 1mdrh8e\n",
      "\n",
      "[583/1593] Collected 3 comments from post 1mybl05\n",
      "\n",
      "[584/1593] Collected 6 comments from post 1mofi2v\n",
      "\n",
      "[585/1593] Collected 78 comments from post 1fbd9qm\n",
      "\n",
      "[586/1593] Collected 40 comments from post z91nwt\n",
      "\n",
      "[587/1593] Collected 0 comments from post 1mu8mjg\n",
      "\n",
      "[588/1593] Collected 5 comments from post 1n0s5sk\n",
      "\n",
      "[589/1593] Collected 14 comments from post 1mbq0xg\n",
      "\n",
      "[590/1593] Collected 68 comments from post 12kwidu\n",
      "\n",
      "[591/1593] Collected 15 comments from post 1mb2fsk\n",
      "\n",
      "[592/1593] Collected 48 comments from post rxu5nj\n",
      "\n",
      "[593/1593] Collected 47 comments from post 12yuwg1\n",
      "\n",
      "[594/1593] Collected 6 comments from post 1mqczoh\n",
      "\n",
      "[595/1593] Collected 84 comments from post 1hamc8j\n",
      "\n",
      "[596/1593] Collected 23 comments from post 1g7mycd\n",
      "\n",
      "[597/1593] Collected 69 comments from post spb5s5\n",
      "\n",
      "[598/1593] Collected 14 comments from post 1minrab\n",
      "\n",
      "[599/1593] Collected 17 comments from post 1mlkvzm\n",
      "\n",
      "[600/1593] Collected 3 comments from post 1mbab25\n",
      "\n",
      "[601/1593] Collected 27 comments from post uldbaq\n",
      "\n",
      "[602/1593] Collected 20 comments from post 1mil2n2\n",
      "\n",
      "[603/1593] Collected 179 comments from post 194jp2h\n",
      "\n",
      "[604/1593] Collected 74 comments from post 1e6iaxu\n",
      "\n",
      "[605/1593] Collected 61 comments from post 1mizl4h\n",
      "\n",
      "[606/1593] Collected 18 comments from post 1n7d3d1\n",
      "\n",
      "[607/1593] Collected 47 comments from post 1emnmok\n",
      "\n",
      "[608/1593] Collected 1 comments from post 1mkurb1\n",
      "\n",
      "[609/1593] Collected 13 comments from post 1mbvkfy\n",
      "\n",
      "[610/1593] Collected 35 comments from post 10mywpn\n",
      "\n",
      "[611/1593] Collected 95 comments from post 1myf2zm\n",
      "\n",
      "[612/1593] Collected 4 comments from post 1mlzf6n\n",
      "\n",
      "[613/1593] Collected 3 comments from post 1mx7y8f\n",
      "\n",
      "[614/1593] Collected 7 comments from post 1mtllwa\n",
      "\n",
      "[615/1593] Collected 2 comments from post 1mbjobl\n",
      "\n",
      "[616/1593] Collected 5 comments from post 1n3cj6x\n",
      "\n",
      "[617/1593] Collected 5 comments from post 1mvof72\n",
      "\n",
      "[618/1593] Collected 32 comments from post 1gjhyz0\n",
      "\n",
      "[619/1593] Collected 4 comments from post 1mhkps0\n",
      "\n",
      "[620/1593] Collected 12 comments from post 1n6jaml\n",
      "\n",
      "[621/1593] Collected 4 comments from post 1mvr9nh\n",
      "\n",
      "[622/1593] Collected 21 comments from post 1maw7cv\n",
      "\n",
      "[623/1593] Collected 7 comments from post 1mzoxm3\n",
      "\n",
      "[624/1593] Collected 79 comments from post 1moirii\n",
      "\n",
      "[625/1593] Collected 5 comments from post 1mq4sht\n",
      "\n",
      "[626/1593] Collected 7 comments from post 1n1ivi1\n",
      "\n",
      "[627/1593] Collected 31 comments from post 1mnc6cm\n",
      "\n",
      "[628/1593] Collected 53 comments from post 11zjmg9\n",
      "\n",
      "[629/1593] Collected 58 comments from post 10iqzr0\n",
      "\n",
      "[630/1593] Collected 36 comments from post 1ghhkh3\n",
      "\n",
      "[631/1593] Collected 3 comments from post 1mmrakh\n",
      "\n",
      "[632/1593] Collected 13 comments from post 1n2au2l\n",
      "\n",
      "[633/1593] Collected 17 comments from post 1mwj809\n",
      "\n",
      "[634/1593] Collected 40 comments from post 18pafsa\n",
      "\n",
      "[635/1593] Collected 117 comments from post 1i3ny8s\n",
      "\n",
      "[636/1593] Collected 33 comments from post 1ms73v1\n",
      "\n",
      "[637/1593] Collected 41 comments from post 1fq8nov\n",
      "\n",
      "[638/1593] Collected 1 comments from post 1n5zq5d\n",
      "\n",
      "[639/1593] Collected 6 comments from post 1mz2z2k\n",
      "\n",
      "[640/1593] Collected 5 comments from post 1mhy992\n",
      "\n",
      "[641/1593] Collected 2 comments from post 1n2i2om\n",
      "\n",
      "[642/1593] Collected 18 comments from post 1mokidc\n",
      "\n",
      "[643/1593] Collected 0 comments from post 1mw0esq\n",
      "\n",
      "[644/1593] Collected 16 comments from post 1mzqso1\n",
      "\n",
      "[645/1593] Collected 39 comments from post 1mnu2rg\n",
      "\n",
      "[646/1593] Collected 19 comments from post 1mk4xtb\n",
      "\n",
      "[647/1593] Collected 14 comments from post 1f5pxn5\n",
      "\n",
      "[648/1593] Collected 43 comments from post 1mum09g\n",
      "\n",
      "[649/1593] Collected 11 comments from post 1mok74h\n",
      "\n",
      "[650/1593] Collected 6 comments from post 1mljcpb\n",
      "\n",
      "[651/1593] Collected 22 comments from post 1mkkyce\n",
      "\n",
      "[652/1593] Collected 12 comments from post 1mjxa6l\n",
      "\n",
      "[653/1593] Collected 32 comments from post 1muex0w\n",
      "\n",
      "[654/1593] Collected 15 comments from post 1ektxnh\n",
      "\n",
      "[655/1593] Collected 9 comments from post 1molp4v\n",
      "\n",
      "[656/1593] Collected 13 comments from post 1n2rykg\n",
      "\n",
      "[657/1593] Collected 39 comments from post 1lhbg7y\n",
      "\n",
      "[658/1593] Collected 27 comments from post 1mocc8m\n",
      "\n",
      "[659/1593] Collected 10 comments from post 1ma0rrn\n",
      "\n",
      "[660/1593] Collected 11 comments from post 1mr12sb\n",
      "\n",
      "[661/1593] Collected 59 comments from post uosm3h\n",
      "\n",
      "[662/1593] Collected 16 comments from post 1n5psds\n",
      "\n",
      "[663/1593] Collected 61 comments from post 1gy2tf9\n",
      "\n",
      "[664/1593] Collected 6 comments from post 1mteg3p\n",
      "\n",
      "[665/1593] Collected 42 comments from post 1mj9xrt\n",
      "\n",
      "[666/1593] Collected 6 comments from post 1ma8r39\n",
      "\n",
      "[667/1593] Collected 24 comments from post 1n5a2r0\n",
      "\n",
      "[668/1593] Collected 17 comments from post 1mhz5hh\n",
      "\n",
      "[669/1593] Collected 0 comments from post 1mc78av\n",
      "\n",
      "[670/1593] Collected 162 comments from post tdwmo3\n",
      "\n",
      "[671/1593] Collected 18 comments from post 1mnwsrt\n",
      "\n",
      "[672/1593] Collected 6 comments from post 1mwa4dk\n",
      "\n",
      "[673/1593] Collected 50 comments from post t9nu3r\n",
      "\n",
      "[674/1593] Collected 14 comments from post 1mquvlm\n",
      "\n",
      "[675/1593] Collected 5 comments from post 1mieu53\n",
      "\n",
      "[676/1593] Collected 44 comments from post winoyq\n",
      "\n",
      "[677/1593] Collected 6 comments from post 1n72lwa\n",
      "\n",
      "[678/1593] Collected 25 comments from post 1n6oxfz\n",
      "\n",
      "[679/1593] Collected 4 comments from post 1mvssqa\n",
      "\n",
      "[680/1593] Collected 19 comments from post 1mt6rmj\n",
      "\n",
      "[681/1593] Collected 3 comments from post 1mpwbcd\n",
      "\n",
      "[682/1593] Collected 2 comments from post 1mw0cse\n",
      "\n",
      "[683/1593] Collected 24 comments from post 1ma194n\n",
      "\n",
      "[684/1593] Collected 5 comments from post 1n2x6e6\n",
      "\n",
      "[685/1593] Collected 33 comments from post 1gkl45b\n",
      "\n",
      "[686/1593] Collected 20 comments from post 1g96aom\n",
      "\n",
      "[687/1593] Collected 38 comments from post 1fgn74a\n",
      "\n",
      "[688/1593] Collected 181 comments from post zr2hx8\n",
      "\n",
      "[689/1593] Collected 13 comments from post 1gzmkmd\n",
      "\n",
      "[690/1593] Collected 143 comments from post ztx3nf\n",
      "\n",
      "[691/1593] Collected 136 comments from post 18zlcen\n",
      "\n",
      "[692/1593] Collected 13 comments from post 1mqn68q\n",
      "\n",
      "[693/1593] Collected 18 comments from post 1mxd7qr\n",
      "\n",
      "[694/1593] Collected 47 comments from post wnh3sp\n",
      "\n",
      "[695/1593] Collected 50 comments from post 1my6yu3\n",
      "\n",
      "[696/1593] Collected 47 comments from post 1mmv378\n",
      "\n",
      "[697/1593] Collected 170 comments from post 1mc6g92\n",
      "\n",
      "[698/1593] Collected 30 comments from post wcrwlv\n",
      "\n",
      "[699/1593] Collected 25 comments from post 1mdo683\n",
      "\n",
      "[700/1593] Collected 27 comments from post 1dx5x17\n",
      "\n",
      "[701/1593] Collected 13 comments from post 1mp1x3o\n",
      "\n",
      "[702/1593] Collected 38 comments from post 1mqn90k\n",
      "\n",
      "[703/1593] Collected 79 comments from post 1cdm549\n",
      "\n",
      "[704/1593] Collected 69 comments from post 1n5jq8w\n",
      "\n",
      "[705/1593] Collected 61 comments from post 1gteqse\n",
      "\n",
      "[706/1593] Collected 11 comments from post 1n3r42m\n",
      "\n",
      "[707/1593] Collected 7 comments from post 1mki8z4\n",
      "\n",
      "[708/1593] Collected 5 comments from post 1mx9c1w\n",
      "\n",
      "[709/1593] Collected 35 comments from post 1fdkp55\n",
      "\n",
      "[710/1593] Collected 166 comments from post 1d59qbn\n",
      "\n",
      "[711/1593] Collected 162 comments from post 17eo775\n",
      "\n",
      "[712/1593] Collected 6 comments from post 1n40rko\n",
      "\n",
      "[713/1593] Collected 8 comments from post 1mr5fp9\n",
      "\n",
      "[714/1593] Collected 40 comments from post 11atop9\n",
      "\n",
      "[715/1593] Collected 5 comments from post 1mt2zr5\n",
      "\n",
      "[716/1593] Collected 20 comments from post 1mux37c\n",
      "\n",
      "[717/1593] Collected 25 comments from post 1n6jtcn\n",
      "\n",
      "[718/1593] Collected 32 comments from post 1gtkn8g\n",
      "\n",
      "[719/1593] Collected 14 comments from post 1n2cxke\n",
      "\n",
      "[720/1593] Collected 2 comments from post 1mlaudc\n",
      "\n",
      "[721/1593] Collected 34 comments from post 1n1bwsu\n",
      "\n",
      "[722/1593] Collected 14 comments from post 1ml0vyn\n",
      "\n",
      "[723/1593] Collected 31 comments from post 1glcwsw\n",
      "\n",
      "[724/1593] Collected 10 comments from post 1mcjdql\n",
      "\n",
      "[725/1593] Collected 3 comments from post 1mka5fv\n",
      "\n",
      "[726/1593] Collected 7 comments from post 1mmpedm\n",
      "\n",
      "[727/1593] Collected 45 comments from post 1gr3n8t\n",
      "\n",
      "[728/1593] Collected 7 comments from post 1mqfvae\n",
      "\n",
      "[729/1593] Collected 22 comments from post 1iz36ne\n",
      "\n",
      "[730/1593] Collected 304 comments from post 18qbvjh\n",
      "\n",
      "[731/1593] Collected 17 comments from post 1m9puef\n",
      "\n",
      "[732/1593] Collected 33 comments from post 1315sdw\n",
      "\n",
      "[733/1593] Collected 2 comments from post 1me1394\n",
      "\n",
      "[734/1593] Collected 12 comments from post 1fwxkpa\n",
      "\n",
      "[735/1593] Collected 15 comments from post 1n08uqp\n",
      "\n",
      "[736/1593] Collected 13 comments from post 1n6pyq3\n",
      "\n",
      "[737/1593] Collected 136 comments from post xz5osn\n",
      "\n",
      "[738/1593] Collected 4 comments from post 1mk2ol8\n",
      "\n",
      "[739/1593] Collected 34 comments from post 1mic8lj\n",
      "\n",
      "[740/1593] Collected 7 comments from post 1myu842\n",
      "\n",
      "[741/1593] Collected 10 comments from post 1n0y8vk\n",
      "\n",
      "[742/1593] Collected 2 comments from post 1mvoufb\n",
      "\n",
      "[743/1593] Collected 40 comments from post wqxthi\n",
      "\n",
      "[744/1593] Collected 20 comments from post 1mbrk68\n",
      "\n",
      "[745/1593] Collected 5 comments from post 1mpm6ie\n",
      "\n",
      "[746/1593] Collected 23 comments from post 1mcj86m\n",
      "\n",
      "[747/1593] Collected 189 comments from post xi5007\n",
      "\n",
      "[748/1593] Collected 26 comments from post 1g5wtnv\n",
      "\n",
      "[749/1593] Collected 0 comments from post 1n2vu7i\n",
      "\n",
      "[750/1593] Collected 27 comments from post 1g6p19t\n",
      "\n",
      "[751/1593] Collected 24 comments from post 1g3jqma\n",
      "\n",
      "[752/1593] Collected 21 comments from post 1mqjodg\n",
      "\n",
      "[753/1593] Collected 6 comments from post 1mhptii\n",
      "\n",
      "[754/1593] Collected 70 comments from post 108e02m\n",
      "\n",
      "[755/1593] Collected 7 comments from post 1gxkwou\n",
      "\n",
      "[756/1593] Collected 20 comments from post 1fm15fi\n",
      "\n",
      "[757/1593] Collected 26 comments from post 1mobdhe\n",
      "\n",
      "[758/1593] Collected 8 comments from post 1mnijwt\n",
      "\n",
      "[759/1593] Collected 9 comments from post 1n4kgx6\n",
      "\n",
      "[760/1593] Collected 195 comments from post 1mud6dy\n",
      "\n",
      "[761/1593] Collected 31 comments from post 1lsdrie\n",
      "\n",
      "[762/1593] Collected 10 comments from post 1mvmn7c\n",
      "\n",
      "[763/1593] Collected 11 comments from post 1mryk21\n",
      "\n",
      "[764/1593] Collected 294 comments from post 126lq3n\n",
      "\n",
      "[765/1593] Collected 14 comments from post 1gpwubf\n",
      "\n",
      "[766/1593] Collected 57 comments from post xlw7yi\n",
      "\n",
      "[767/1593] Collected 4 comments from post 1mt416g\n",
      "\n",
      "[768/1593] Collected 52 comments from post 1231w9a\n",
      "\n",
      "[769/1593] Collected 11 comments from post 1n20ezn\n",
      "\n",
      "[770/1593] Collected 66 comments from post s36cm5\n",
      "\n",
      "[771/1593] Collected 2 comments from post 1mpg58m\n",
      "\n",
      "[772/1593] Collected 12 comments from post 1mnu0of\n",
      "\n",
      "[773/1593] Collected 113 comments from post 1l40ybw\n",
      "\n",
      "[774/1593] Collected 27 comments from post xoznkd\n",
      "\n",
      "[775/1593] Collected 37 comments from post 1fp2k0j\n",
      "\n",
      "[776/1593] Collected 10 comments from post 1moh0q7\n",
      "\n",
      "[777/1593] Collected 90 comments from post 197ed8g\n",
      "\n",
      "[778/1593] Collected 2 comments from post 1n5xfj2\n",
      "\n",
      "[779/1593] Collected 0 comments from post 1n18qvc\n",
      "\n",
      "[780/1593] Collected 79 comments from post 1hyytud\n",
      "\n",
      "[781/1593] Collected 48 comments from post 1ectroi\n",
      "\n",
      "[782/1593] Collected 1 comments from post 1mfkhv4\n",
      "\n",
      "[783/1593] Collected 6 comments from post 1mgn0e1\n",
      "\n",
      "[784/1593] Collected 65 comments from post 1mxap8h\n",
      "\n",
      "[785/1593] Collected 16 comments from post 1mfh1nk\n",
      "\n",
      "[786/1593] Collected 8 comments from post 1ml619t\n",
      "\n",
      "[787/1593] Collected 64 comments from post 1i2uyzl\n",
      "\n",
      "[788/1593] Collected 60 comments from post xs0vwv\n",
      "\n",
      "[789/1593] Collected 11 comments from post 1mnnd3l\n",
      "\n",
      "[790/1593] Collected 8 comments from post 1md5kq5\n",
      "\n",
      "[791/1593] Collected 24 comments from post 1mvd33l\n",
      "\n",
      "[792/1593] Collected 29 comments from post 1jlge10\n",
      "\n",
      "[793/1593] Collected 37 comments from post 1jqp1jg\n",
      "\n",
      "[794/1593] Collected 10 comments from post 1mpx71q\n",
      "\n",
      "[795/1593] Collected 19 comments from post 1go9zie\n",
      "\n",
      "[796/1593] Collected 60 comments from post 18xvrly\n",
      "\n",
      "[797/1593] Collected 127 comments from post 1gjqjbj\n",
      "\n",
      "[798/1593] Collected 47 comments from post 1figry9\n",
      "\n",
      "[799/1593] Collected 43 comments from post 1m9x9jg\n",
      "\n",
      "[800/1593] Collected 32 comments from post 1mfzlf8\n",
      "\n",
      "[801/1593] Collected 244 comments from post 1et4ns0\n",
      "\n",
      "[802/1593] Collected 32 comments from post 1mnj6iq\n",
      "\n",
      "[803/1593] Collected 47 comments from post 1molsmo\n",
      "\n",
      "[804/1593] Collected 4 comments from post 1n6sxm1\n",
      "\n",
      "[805/1593] Collected 171 comments from post 1c860wn\n",
      "\n",
      "[806/1593] Collected 30 comments from post 1mve4ph\n",
      "\n",
      "[807/1593] Collected 4 comments from post 1n2q7uo\n",
      "\n",
      "[808/1593] Collected 5 comments from post 1mxjhfs\n",
      "\n",
      "[809/1593] Collected 4 comments from post 1mr0y5d\n",
      "\n",
      "[810/1593] Collected 46 comments from post 1hv2y9a\n",
      "\n",
      "[811/1593] Collected 60 comments from post uzpf8c\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[100], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Get all comments from all posts\u001b[39;00m\n\u001b[0;32m      3\u001b[0m all_post_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(posts_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpost_id\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m----> 5\u001b[0m comments_df \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_comments_from_posts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_post_ids\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[53], line 14\u001b[0m, in \u001b[0;36mfetch_comments_from_posts\u001b[1;34m(post_ids, max_comments_per_post)\u001b[0m\n\u001b[0;32m     11\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(post_ids)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, pid \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(post_ids, start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m---> 14\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_comments_single_post\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_comments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_comments_per_post\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m     all_dfs\u001b[38;5;241m.\u001b[39mappend(df)\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] Collected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m comments from post \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[52], line 11\u001b[0m, in \u001b[0;36mfetch_comments_single_post\u001b[1;34m(post_id, max_comments)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03mFetch all comments for a single post.\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      9\u001b[0m submission \u001b[38;5;241m=\u001b[39m reddit\u001b[38;5;241m.\u001b[39msubmission(\u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39mpost_id)\n\u001b[1;32m---> 11\u001b[0m \u001b[43msubmission\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomments\u001b[49m\u001b[38;5;241m.\u001b[39mreplace_more(limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# expand all MoreComments\u001b[39;00m\n\u001b[0;32m     13\u001b[0m rows \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     14\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lulu_env\\lib\\site-packages\\praw\\models\\reddit\\base.py:38\u001b[0m, in \u001b[0;36mRedditBase.__getattr__\u001b[1;34m(self, attribute)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the value of ``attribute``.\"\"\"\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m attribute\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetched:\n\u001b[1;32m---> 38\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, attribute)\n\u001b[0;32m     40\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattribute\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lulu_env\\lib\\site-packages\\praw\\models\\reddit\\submission.py:726\u001b[0m, in \u001b[0;36mSubmission._fetch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    725\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_fetch\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 726\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fetch_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    727\u001b[0m     submission_listing, comment_listing \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m    728\u001b[0m     comment_listing \u001b[38;5;241m=\u001b[39m Listing(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reddit, _data\u001b[38;5;241m=\u001b[39mcomment_listing[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lulu_env\\lib\\site-packages\\praw\\models\\reddit\\submission.py:744\u001b[0m, in \u001b[0;36mSubmission._fetch_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    742\u001b[0m params\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_additional_fetch_params\u001b[38;5;241m.\u001b[39mcopy())\n\u001b[0;32m    743\u001b[0m path \u001b[38;5;241m=\u001b[39m API_PATH[name]\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfields)\n\u001b[1;32m--> 744\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reddit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lulu_env\\lib\\site-packages\\praw\\util\\deprecate_args.py:46\u001b[0m, in \u001b[0;36m_deprecate_args.<locals>.wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     39\u001b[0m     arg_string \u001b[38;5;241m=\u001b[39m _generate_arg_string(_old_args[: \u001b[38;5;28mlen\u001b[39m(args)])\n\u001b[0;32m     40\u001b[0m     warn(\n\u001b[0;32m     41\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPositional arguments for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m will no longer be\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     42\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m supported in PRAW 8.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCall this function with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg_string\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[0;32m     44\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m     45\u001b[0m     )\n\u001b[1;32m---> 46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(_old_args, args)), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lulu_env\\lib\\site-packages\\praw\\reddit.py:963\u001b[0m, in \u001b[0;36mReddit.request\u001b[1;34m(self, data, files, json, method, params, path)\u001b[0m\n\u001b[0;32m    961\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ClientException(msg)\n\u001b[0;32m    962\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 963\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_core\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    965\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m BadRequest \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[0;32m    972\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lulu_env\\lib\\site-packages\\prawcore\\sessions.py:328\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, path, data, files, json, params, timeout)\u001b[0m\n\u001b[0;32m    326\u001b[0m     json[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapi_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    327\u001b[0m url \u001b[38;5;241m=\u001b[39m urljoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_requestor\u001b[38;5;241m.\u001b[39moauth_url, path)\n\u001b[1;32m--> 328\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_with_retries\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lulu_env\\lib\\site-packages\\prawcore\\sessions.py:234\u001b[0m, in \u001b[0;36mSession._request_with_retries\u001b[1;34m(self, data, files, json, method, params, timeout, url, retry_strategy_state)\u001b[0m\n\u001b[0;32m    232\u001b[0m retry_strategy_state\u001b[38;5;241m.\u001b[39msleep()\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_request(data, method, params, url)\n\u001b[1;32m--> 234\u001b[0m response, saved_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry_strategy_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    245\u001b[0m do_retry \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m codes[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munauthorized\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lulu_env\\lib\\site-packages\\prawcore\\sessions.py:186\u001b[0m, in \u001b[0;36mSession._make_request\u001b[1;34m(self, data, files, json, method, params, retry_strategy_state, timeout, url)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_make_request\u001b[39m(\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    176\u001b[0m     data: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    183\u001b[0m     url: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m    184\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[Response, \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m]:\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 186\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rate_limiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_requestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_header_callback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m            \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m            \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m            \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m         log\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[0;32m    199\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResponse: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m bytes) (rst-\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m:rem-\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m:used-\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m ratelimit) at \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    200\u001b[0m             response\u001b[38;5;241m.\u001b[39mstatus_code,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    205\u001b[0m             time\u001b[38;5;241m.\u001b[39mtime(),\n\u001b[0;32m    206\u001b[0m         )\n\u001b[0;32m    207\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lulu_env\\lib\\site-packages\\prawcore\\rate_limit.py:47\u001b[0m, in \u001b[0;36mRateLimiter.call\u001b[1;34m(self, request_function, set_header_callback, *args, **kwargs)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelay()\n\u001b[0;32m     46\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m set_header_callback()\n\u001b[1;32m---> 47\u001b[0m response \u001b[38;5;241m=\u001b[39m request_function(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(response\u001b[38;5;241m.\u001b[39mheaders)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lulu_env\\lib\\site-packages\\prawcore\\requestor.py:68\u001b[0m, in \u001b[0;36mRequestor.request\u001b[1;34m(self, timeout, *args, **kwargs)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Issue the HTTP request capturing any errors that may occur.\"\"\"\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_http\u001b[38;5;241m.\u001b[39mrequest(\u001b[38;5;241m*\u001b[39margs, timeout\u001b[38;5;241m=\u001b[39mtimeout \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:  \u001b[38;5;66;03m# noqa: BLE001\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RequestException(exc, args, kwargs) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lulu_env\\lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lulu_env\\lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lulu_env\\lib\\site-packages\\requests\\adapters.py:644\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    641\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    643\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 644\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    645\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    646\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    647\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    648\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    651\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    652\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    653\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    654\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    655\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    658\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    659\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lulu_env\\lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    784\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    788\u001b[0m     conn,\n\u001b[0;32m    789\u001b[0m     method,\n\u001b[0;32m    790\u001b[0m     url,\n\u001b[0;32m    791\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    792\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    793\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    794\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    795\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    796\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    797\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    798\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    800\u001b[0m )\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    803\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lulu_env\\lib\\site-packages\\urllib3\\connectionpool.py:534\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 534\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lulu_env\\lib\\site-packages\\urllib3\\connection.py:565\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    562\u001b[0m _shutdown \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshutdown\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    564\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 565\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    568\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lulu_env\\lib\\http\\client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1373\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1374\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1375\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1376\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1377\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lulu_env\\lib\\http\\client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lulu_env\\lib\\http\\client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lulu_env\\lib\\socket.py:717\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    716\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 717\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    718\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    719\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lulu_env\\lib\\ssl.py:1307\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1304\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1305\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1306\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lulu_env\\lib\\ssl.py:1163\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1161\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1163\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1164\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1165\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Get all comments from all posts\n",
    "\n",
    "all_post_ids = list(set(posts_df['post_id']))\n",
    "\n",
    "comments_df = fetch_comments_from_posts(all_post_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d500be77-58da-4314-bb4d-a152340f523e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Number of records in the comments dataframe is: 15545\n",
      "\n",
      "\n",
      "Number of features in the comments dataframe is: 10\n",
      "\n",
      "The columns in the comments dataframe are: Index(['post_id', 'comment_id', 'timestamp', 'author', 'body', 'score',\n",
      "       'is_submitter', 'parent_id', 'permalink', 'depth'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      " Other info about comments dataframe:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15545 entries, 0 to 15544\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Non-Null Count  Dtype              \n",
      "---  ------        --------------  -----              \n",
      " 0   post_id       15545 non-null  object             \n",
      " 1   comment_id    15545 non-null  object             \n",
      " 2   timestamp     15545 non-null  datetime64[ns, UTC]\n",
      " 3   author        15362 non-null  object             \n",
      " 4   body          15545 non-null  object             \n",
      " 5   score         15545 non-null  int64              \n",
      " 6   is_submitter  15545 non-null  bool               \n",
      " 7   parent_id     15545 non-null  object             \n",
      " 8   permalink     15545 non-null  object             \n",
      " 9   depth         15545 non-null  int64              \n",
      "dtypes: bool(1), datetime64[ns, UTC](1), int64(2), object(6)\n",
      "memory usage: 1.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Basic statistical info about comments dataframe:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15545.000000</td>\n",
       "      <td>15545.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.361016</td>\n",
       "      <td>0.794918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.568250</td>\n",
       "      <td>1.118902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-56.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>904.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              score         depth\n",
       "count  15545.000000  15545.000000\n",
       "mean       4.361016      0.794918\n",
       "std       13.568250      1.118902\n",
       "min      -56.000000      0.000000\n",
       "25%        1.000000      0.000000\n",
       "50%        2.000000      0.000000\n",
       "75%        3.000000      1.000000\n",
       "max      904.000000      9.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Sample of records in the comments dataframe:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "      <th>score</th>\n",
       "      <th>is_submitter</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>permalink</th>\n",
       "      <th>depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1n4i5ke</td>\n",
       "      <td>nbl94po</td>\n",
       "      <td>2025-08-31 01:27:30+00:00</td>\n",
       "      <td>AutoModerator</td>\n",
       "      <td>Hello! This is a comment to let you know that ...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>t3_1n4i5ke</td>\n",
       "      <td>https://www.reddit.com/r/lululemon/comments/1n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1n4i5ke</td>\n",
       "      <td>nbl9wdc</td>\n",
       "      <td>2025-08-31 01:32:16+00:00</td>\n",
       "      <td>Humble-Bus3726</td>\n",
       "      <td>What kind of dog tho!</td>\n",
       "      <td>63</td>\n",
       "      <td>False</td>\n",
       "      <td>t3_1n4i5ke</td>\n",
       "      <td>https://www.reddit.com/r/lululemon/comments/1n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1n4i5ke</td>\n",
       "      <td>nblb2cw</td>\n",
       "      <td>2025-08-31 01:39:23+00:00</td>\n",
       "      <td>thevffice</td>\n",
       "      <td>omg the korok!!! lovelovelove ü•πü•πü•π where did yo...</td>\n",
       "      <td>47</td>\n",
       "      <td>False</td>\n",
       "      <td>t3_1n4i5ke</td>\n",
       "      <td>https://www.reddit.com/r/lululemon/comments/1n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1n4i5ke</td>\n",
       "      <td>nblbqh1</td>\n",
       "      <td>2025-08-31 01:43:32+00:00</td>\n",
       "      <td>Careful_Koala7995</td>\n",
       "      <td>I had a young girl with her friends tell me sh...</td>\n",
       "      <td>47</td>\n",
       "      <td>False</td>\n",
       "      <td>t3_1n4i5ke</td>\n",
       "      <td>https://www.reddit.com/r/lululemon/comments/1n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1n4i5ke</td>\n",
       "      <td>nblbpiw</td>\n",
       "      <td>2025-08-31 01:43:22+00:00</td>\n",
       "      <td>Pd_unicorn</td>\n",
       "      <td>Love your outfit too!</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>t3_1n4i5ke</td>\n",
       "      <td>https://www.reddit.com/r/lululemon/comments/1n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id comment_id                 timestamp             author  \\\n",
       "0  1n4i5ke    nbl94po 2025-08-31 01:27:30+00:00      AutoModerator   \n",
       "1  1n4i5ke    nbl9wdc 2025-08-31 01:32:16+00:00     Humble-Bus3726   \n",
       "2  1n4i5ke    nblb2cw 2025-08-31 01:39:23+00:00          thevffice   \n",
       "3  1n4i5ke    nblbqh1 2025-08-31 01:43:32+00:00  Careful_Koala7995   \n",
       "4  1n4i5ke    nblbpiw 2025-08-31 01:43:22+00:00         Pd_unicorn   \n",
       "\n",
       "                                                body  score  is_submitter  \\\n",
       "0  Hello! This is a comment to let you know that ...      1         False   \n",
       "1                              What kind of dog tho!     63         False   \n",
       "2  omg the korok!!! lovelovelove ü•πü•πü•π where did yo...     47         False   \n",
       "3  I had a young girl with her friends tell me sh...     47         False   \n",
       "4                              Love your outfit too!     10         False   \n",
       "\n",
       "    parent_id                                          permalink  depth  \n",
       "0  t3_1n4i5ke  https://www.reddit.com/r/lululemon/comments/1n...      0  \n",
       "1  t3_1n4i5ke  https://www.reddit.com/r/lululemon/comments/1n...      0  \n",
       "2  t3_1n4i5ke  https://www.reddit.com/r/lululemon/comments/1n...      0  \n",
       "3  t3_1n4i5ke  https://www.reddit.com/r/lululemon/comments/1n...      0  \n",
       "4  t3_1n4i5ke  https://www.reddit.com/r/lululemon/comments/1n...      0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Examine comments dataframe\n",
    "\n",
    "examine_df('comments dataframe', comments_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1a5d092b-a0ff-40d9-be8b-b17587f9197f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save posts dataframe as a csv\n",
    "\n",
    "posts_df.to_csv(f\"{PATH}/posts.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "81bbca65-5e3c-427b-9231-6489293e839c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Save comments dataframe as a csv\n",
    "\n",
    "comments_df.to_csv(f\"{PATH}/comments.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (lulu_env)",
   "language": "python",
   "name": "lulu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
