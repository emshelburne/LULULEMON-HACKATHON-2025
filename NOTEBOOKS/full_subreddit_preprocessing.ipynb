{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f45f844-7678-47d9-81c9-492d8571f422",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9ac48e06-1b3a-4dd8-ba25-f8cc9daee548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "# General\n",
    "import json\n",
    "import zstandard as zstd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from typing import Optional\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# NLP\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim import corpora\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfa28980-b7fb-4c70-92dd-ff0903377914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set user's data path\n",
    "\n",
    "PATH = f\"C:/Users/emshe/Desktop/BRAINSTATION/LULULEMON/DATA/TORRENTED/reddit/subreddits24/lululemon_submissions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef3de349-221d-42dd-92ac-bf8a5066d110",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\emshe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download NLTK files (run once)\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e7c212-fa67-40e1-872f-bfd63fe1382a",
   "metadata": {},
   "source": [
    "## Helper functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a7ec57d-8299-43dd-9343-252d47d0bae0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Function to clean text\n",
    "\n",
    "def clean_text(s: str | None) -> str | None:\n",
    "    \n",
    "    '''\n",
    "    Clean string by substituting spaces for problematic characters\n",
    "    '''\n",
    "    \n",
    "    if s is None:\n",
    "        return None\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b388f449-e518-4bf3-8680-e6024a8e3608",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Function to get datetime from UTC timestamp\n",
    "\n",
    "def dt_from_epoch(ts: Optional[int]):\n",
    "\n",
    "    \"\"\"\n",
    "    Convert timestamp to pd.datetime format\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    if ts is None:\n",
    "        return None\n",
    "    return pd.to_datetime(ts, unit=\"s\", utc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c31afab8-4692-43da-87bc-0723484c41b8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Function to examine dataframes\n",
    "\n",
    "def examine_df(name,df,\n",
    "               include_stats = True,\n",
    "               include_sample = True):\n",
    "    \n",
    "    \"\"\"\n",
    "    Check basic info about a dataframe df\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n\\nNumber of records in the {name} is: {len(df)}\\n\")\n",
    "    print(f\"\\nNumber of features in the {name} is: {len(df.columns)}\\n\")\n",
    "    print(f\"The columns in the {name} are: {df.columns}\\n\")\n",
    "    print(f\"\\n Other info about {name}:\\n\")\n",
    "    display(df.info())\n",
    "    if include_stats == True:\n",
    "        print(f'\\n Basic statistical info about {name}:\\n')\n",
    "        display(df.describe())\n",
    "    if include_sample == True:\n",
    "        print(f\"\\n\\nSample of records in the {name}:\")\n",
    "        display(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94e964fb-cd5c-4f31-a3de-b34833a66d2d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Function to get sample from text column\n",
    "\n",
    "def get_text_samples(df: pd.DataFrame, text_col: str, n: int) -> None:\n",
    "\n",
    "    '''\n",
    "    Print n samples from a text column in a dataframe\n",
    "    '''\n",
    "\n",
    "    # Ensure pandas doesn't truncate text\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    \n",
    "    # Sample and print 5 full negative reviews\n",
    "    print(\"Sample text data:\\n\\n\")\n",
    "    sample = df[text_col].sample(n)\n",
    "    for i, description in enumerate(sample, 1):\n",
    "        print(f\"Text sample {i}:\\n\\n\\n{description}\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f37be0d6-5f22-4ed3-87e1-b4a69677e0b0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Function for categorical bar graph\n",
    "\n",
    "def bar_graph(df: pd.DataFrame, col: str) -> None:\n",
    "\n",
    "    \"\"\"\n",
    "    Generate bar graph for categorical column in a dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    if col not in df.columns:\n",
    "        raise ValueError(f\"Column '{col}' not found in dataframe\")\n",
    "\n",
    "    counts = posts_df[col].value_counts()\n",
    "    \n",
    "    plt.figure(figsize=(10,6))\n",
    "    counts.plot(kind=\"bar\")\n",
    "    plt.title(f\"Distribution of {col.title()}\")\n",
    "    plt.xlabel(f\"{col.title()}\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc8ae594-562e-49e5-a6e3-0f7c126993ca",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Define function to plot histogram for numeric columns\n",
    "\n",
    "def histogram(df: pd.DataFrame, \n",
    "             col: str,\n",
    "            bins: int = 30,\n",
    "             log: bool = False) -> None:\n",
    "    \n",
    "    \"\"\"\n",
    "    Generate a histogram for a numeric column in a dataframe.\n",
    "    \"\"\"\n",
    "    \n",
    "    if col not in df.columns:\n",
    "        raise ValueError(f\"Column '{col}' not found in dataframe\")\n",
    "    \n",
    "    plt.figure(figsize=(8, 5))\n",
    "    df[col].dropna().hist(bins=bins, edgecolor=\"black\", log=log)\n",
    "    plt.title(f\"Histogram of {col.title()}\")\n",
    "    plt.xlabel(col.title())\n",
    "    plt.ylabel(\"Log(Frequency)\" if log else \"Frequency\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a314a84b-a9ef-4b8c-b3f7-6fc4a06bb7b0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Function to load ndjson\n",
    "\n",
    "def load_plain_ndjson(path: str, limit: Optional[int] = None) -> pd.DataFrame:\n",
    "    \n",
    "    \"\"\"\n",
    "    Load a plain-text NDJSON file line by line into a DataFrame.\n",
    "    \"\"\"\n",
    "    \n",
    "    rows = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for i, line in enumerate(f, start=1):\n",
    "            if not line.strip():\n",
    "                continue\n",
    "            obj = json.loads(line)\n",
    "\n",
    "            rows.append({\n",
    "                \"post_id\": obj.get(\"id\"),\n",
    "                \"timestamp\": dt_from_epoch(obj.get(\"created_utc\")),\n",
    "                \"author\": obj.get(\"author\"),\n",
    "                \"title\": obj.get(\"title\"),\n",
    "                \"text\": obj.get(\"selftext\"),\n",
    "                \"score\": obj.get(\"score\"),\n",
    "                \"num_comments\": obj.get(\"num_comments\"),\n",
    "                \"permalink\": obj.get(\"permalink\"),\n",
    "                \"subreddit\": obj.get(\"subreddit\"),\n",
    "            })\n",
    "\n",
    "            if limit and i >= limit:\n",
    "                break\n",
    "\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcc6245-b542-4dd5-8e0d-0f05a02f765f",
   "metadata": {},
   "source": [
    "## Load and Inspect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "efffc6ad-ecdd-4a46-8730-a7ea402b83a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load clean data\n",
    "\n",
    "lulu_df = pd.read_parquet(\"lululemon_submissions_clean.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0925c71e-8b94-41d1-a28b-f6df482c8149",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Number of records in the lulu dataframe is: 57984\n",
      "\n",
      "\n",
      "Number of features in the lulu dataframe is: 6\n",
      "\n",
      "The columns in the lulu dataframe are: Index(['post_id', 'timestamp', 'title', 'text', 'score', 'num_comments'], dtype='object')\n",
      "\n",
      "\n",
      " Other info about lulu dataframe:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 57984 entries, 0 to 57983\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype              \n",
      "---  ------        --------------  -----              \n",
      " 0   post_id       57984 non-null  object             \n",
      " 1   timestamp     57984 non-null  datetime64[ns, UTC]\n",
      " 2   title         57984 non-null  object             \n",
      " 3   text          57984 non-null  object             \n",
      " 4   score         57984 non-null  int64              \n",
      " 5   num_comments  57984 non-null  int64              \n",
      "dtypes: datetime64[ns, UTC](1), int64(2), object(3)\n",
      "memory usage: 2.7+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Basic statistical info about lulu dataframe:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>57984.000000</td>\n",
       "      <td>57984.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>23.446071</td>\n",
       "      <td>14.705126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>87.240166</td>\n",
       "      <td>40.279924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11864.000000</td>\n",
       "      <td>1987.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              score  num_comments\n",
       "count  57984.000000  57984.000000\n",
       "mean      23.446071     14.705126\n",
       "std       87.240166     40.279924\n",
       "min        0.000000      0.000000\n",
       "25%        1.000000      2.000000\n",
       "50%        3.000000      6.000000\n",
       "75%       13.000000     13.000000\n",
       "max    11864.000000   1987.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Sample of records in the lulu dataframe:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eielly</td>\n",
       "      <td>2020-01-01 05:33:25+00:00</td>\n",
       "      <td>Monthly Sales Post- January</td>\n",
       "      <td>FS: Aligns sz 4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eii06s</td>\n",
       "      <td>2020-01-01 12:46:35+00:00</td>\n",
       "      <td>Major problem falling down leggings?</td>\n",
       "      <td>Hello, over the last year I have been ordering...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eijtca</td>\n",
       "      <td>2020-01-01 16:00:56+00:00</td>\n",
       "      <td>Tops for yoga</td>\n",
       "      <td>I have a couple swiftly tech racerbacks for ho...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eikiew</td>\n",
       "      <td>2020-01-01 16:59:27+00:00</td>\n",
       "      <td>ABC Pants - Sizing</td>\n",
       "      <td>Hey all,\\n\\nI recently received ABC pants (siz...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eil4bb</td>\n",
       "      <td>2020-01-01 17:46:20+00:00</td>\n",
       "      <td>Certain Aligns colours with thicker fabric?</td>\n",
       "      <td>Hi lemonheads :D\\n\\nI was wondering if anyone ...</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  post_id                 timestamp  \\\n",
       "0  eielly 2020-01-01 05:33:25+00:00   \n",
       "1  eii06s 2020-01-01 12:46:35+00:00   \n",
       "2  eijtca 2020-01-01 16:00:56+00:00   \n",
       "3  eikiew 2020-01-01 16:59:27+00:00   \n",
       "4  eil4bb 2020-01-01 17:46:20+00:00   \n",
       "\n",
       "                                         title  \\\n",
       "0                  Monthly Sales Post- January   \n",
       "1         Major problem falling down leggings?   \n",
       "2                                Tops for yoga   \n",
       "3                           ABC Pants - Sizing   \n",
       "4  Certain Aligns colours with thicker fabric?   \n",
       "\n",
       "                                                text  score  num_comments  \n",
       "0                                    FS: Aligns sz 4      1             7  \n",
       "1  Hello, over the last year I have been ordering...      0             6  \n",
       "2  I have a couple swiftly tech racerbacks for ho...      3             4  \n",
       "3  Hey all,\\n\\nI recently received ABC pants (siz...      1             6  \n",
       "4  Hi lemonheads :D\\n\\nI was wondering if anyone ...      3            11  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Examine data\n",
    "\n",
    "examine_df('lulu dataframe', lulu_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5177d54-a7f7-4cdd-9b92-68cfc30587a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy original dataframe\n",
    "\n",
    "og_lulu_df = lulu_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6023f0-b33e-459d-9c91-7bb61ba1f393",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "73e6c995-fd90-4ae2-92fb-7abf829b6599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define stop word list, lemmatizer, and regex\n",
    "\n",
    "# Stopwords\n",
    "custom_stop_words = ['lululemon', 'lulu']  # Add any brand boilerplate tokens here\n",
    "base_stops = set(stopwords.words(\"english\"))\n",
    "base_stops -= {\"no\", \"nor\", \"not\", \"never\"}       # Keep negations\n",
    "stop_words = base_stops.union(custom_stop_words)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Precompile regex\n",
    "_link = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "_nonalpha = re.compile(r'[^a-z\\s]')\n",
    "_spaces = re.compile(r'\\s+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f8d60460-b4d5-4a6b-8630-198dca17822d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define text preprocessor\n",
    "\n",
    "def preprocess(text: str) -> str:\n",
    "\n",
    "    \"\"\"\n",
    "    Preprocess text before modeling\n",
    "    \"\"\"\n",
    "    \n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = _link.sub(\" \", text)         # Remove links\n",
    "    text = _nonalpha.sub(\" \", text)     # Keep only letters/spaces\n",
    "    tokens = []\n",
    "    for t in text.split():\n",
    "        if t in stop_words or len(t) < 3:\n",
    "            continue\n",
    "        t = lemmatizer.lemmatize(t)\n",
    "        tokens.append(t)\n",
    "    return _spaces.sub(\" \", \" \".join(tokens)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "72a9bea5-1541-4a16-8e77-7f8beb48bb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply text preprocessing\n",
    "\n",
    "lulu_df[\"clean_text\"] = lulu_df[\"title\"].fillna(\"\") + \" \" + lulu_df[\"text\"].fillna(\"\")\n",
    "lulu_df[\"clean_text\"] = lulu_df[\"clean_text\"].apply(preprocess)\n",
    "\n",
    "# drop docs with <5 tokens to reduce noise\n",
    "lulu_df = lulu_df[lulu_df[\"clean_text\"].str.split().str.len() >= 5].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "46d8da26-6a21-4296-9af5-c2328ec2da07",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample text data:\n",
      "\n",
      "\n",
      "Text sample 1:\n",
      "\n",
      "\n",
      "fell gymsharks black friday sale nope soo ordered gymshark set black friday sale curious wanted try got adapt marl seamless legging bra top material itchy squat seam feel look like pulling apart followed size chart wont lie look cute quality not def overhyped imo feel like couple year ago think decent try back anyone else similar experience gymshark anyone actually like would love hear thought\n",
      "\n",
      "\n",
      "\n",
      "Text sample 2:\n",
      "\n",
      "\n",
      "store try softstreme pintuck midrise pant bone need good steam excuse wrinkle pick probably comfy importantly versatile back pocket make look like trouser\n",
      "\n",
      "\n",
      "\n",
      "Text sample 3:\n",
      "\n",
      "\n",
      "good morning leg day today track high rise short white free wild bra dark forest green\n",
      "\n",
      "\n",
      "\n",
      "Text sample 4:\n",
      "\n",
      "\n",
      "scuba hoodie define jacket actual hoodies sweater looking scuba hoodie scuba half zip black debating two like better tend prefer crop leaning towards zip want hear pro con\n",
      "\n",
      "\n",
      "\n",
      "Text sample 5:\n",
      "\n",
      "\n",
      "bone nulu set purchased back wmtm bone french terry shrug flow nulu nulu mesh yoga short definitely one favorite\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check some examples\n",
    "\n",
    "get_text_samples(lulu_df, 'clean_text', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604b8fd9-8b5f-4853-aa8a-75ff43e17627",
   "metadata": {},
   "source": [
    "## Build Dictionary and Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ad115157-1c09-4811-a52a-727a98f748aa",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Collect tokenized docs\n",
    "\n",
    "tokenized_docs = [doc.split() for doc in lulu_df[\"clean_text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7ae769bd-05cb-49af-be18-116d1fe5b5c0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Build bigram detector\n",
    "\n",
    "bigram = Phrases(tokenized_docs, min_count=10, threshold=10)  \n",
    "bigram_mod = Phraser(bigram)\n",
    "\n",
    "# Apply the trained model\n",
    "tokenized_bigrams = [bigram_mod[doc] for doc in tokenized_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "de8ee4f7-834a-4222-ac7e-cfd09c469f9c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Add bigram text back to dataframe\n",
    "\n",
    "lulu_df[\"clean_text_bigram\"] = [\" \".join(doc) for doc in tokenized_bigrams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "284f27ce-6c58-4933-9182-41c4dec0cede",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample text data:\n",
      "\n",
      "\n",
      "Text sample 1:\n",
      "\n",
      "\n",
      "faded_zap ebb available dublin stone ridge mall location stopped several faded_zap merlot golden_sand black tidewater_teal ebb call send_sale\n",
      "\n",
      "\n",
      "\n",
      "Text sample 2:\n",
      "\n",
      "\n",
      "true trouser crop wondering anyone knew inseam not regular_length cropped one\n",
      "\n",
      "\n",
      "\n",
      "Text sample 3:\n",
      "\n",
      "\n",
      "size size aligned_midi dress size size love see belly_button would sizing_help\n",
      "\n",
      "\n",
      "\n",
      "Text sample 4:\n",
      "\n",
      "\n",
      "morning run fit swiftly_tech short_sleeve shirt race_length speed\n",
      "\n",
      "\n",
      "\n",
      "Text sample 5:\n",
      "\n",
      "\n",
      "anyone_know style top found top social_medium similar beyond_yoga fit included release cannot_find much thanks\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check some examples\n",
    "\n",
    "get_text_samples(lulu_df, 'clean_text_bigram', 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (lulu_env)",
   "language": "python",
   "name": "lulu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
